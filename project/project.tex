% arara: lualatex: { shell: true, synctex: true, interaction: nonstopmode }
% arara: bibtex
% arara: makeglossaries
% arara: makeindex
% arara: lualatex: { shell: true, synctex: true, interaction: nonstopmode }
% arara: lualatex: { shell: true, synctex: true, interaction: nonstopmode }
\documentclass[11pt, a4paper, oneside, twocolumn]{report}
% .  ___   ___        ___  ___  ___   ___  ___  ___   ___              ___         ___   ___   ___ 
% . |   |=|_.'   .'|=|_.' `._|=|   |=|_.' `._|=|   |=|_.'   .'|   .'| |   |   .'|=|_.'  |   |=|_.' 
% . `.  |      .'  |  ___      |   |           |   |      .'  | .'  |\|   | .'  |___    `.  |      
% .   `.|=|`.  |   |=|_.'      |   |           |   |      |   | |   | |   | |   |`._|=.   `.|=|`.  
% .  ___  |  `.|   |  ___      `.  |           `.  |      |   | |   | |  .' `.  |  __||  ___  |  `.
% .  `._|=|___||___|=|_.'        `.|             `.|      |___| |___| |.'     `.|=|_.''  `._|=|___|
% .                                                                                                
%% packages --------------------------------------------------------------------
\usepackage{hyphenations} % thats my own hyphenation list
% \usepackage[english]{babel}
\usepackage[font={it}]{caption}
\usepackage[noend]{algpseudocode}
\usepackage[chapter]{mytodo} % thats my own todo package based on easy-todo
\usepackage{
  amsmath,
  amssymb,
  graphicx,
  hhline,
  hyphenat,
  ifdraft,
  listings,
  makeidx,
  minted,
  pdfpages,
  pgfplots,
  siunitx,
  subcaption,
  tabularx,
  tikzinput,
  xcolor}
\usepackage[nottoc]{tocbibind} % hide toc itself from toc
\usepackage[hidelinks]{hyperref} % always load last!
\usepackage[acronym,nomain,toc]{glossaries} % always load after hyperref!
%% settings --------------------------------------------------------------------
\pgfplotsset{%
  width  = \textwidth,
  height = \textwidth,
  compat = 1.17,
  colormap name = viridis,
  cycle list name = exotic,
  table/search path={data},
} % TikZ doesnt know the twocolumn thing
\usetikzlibrary{external}
\usetikzlibrary{calc}
\tikzexternalize[optimize=true,prefix=tikz/] % externalize tikz, much faster, many conflicts!
\setcounter{secnumdepth}{2} % set level of depth for numbering
\graphicspath{{figures/}}
\input{listingsrc.tex} % a lot of listing options
\renewcommand{\arraystretch}{1.2} % streches row heigth in arrays (and tables)
\DeclareSIUnit\molar{\mole\per\cubic\deci\metre}
\DeclareSIUnit\Molar{\textsc{m}}
\DeclareSIUnit\NA{\textsc{na}}
%% makros ----------------------------------------------------------------------
\renewcommand{\b}{\textbf}
\renewcommand{\u}{\underline}
\renewcommand{\tt}{\texttt}
\renewcommand{\t}{\todo}
\newcommand{\e}{\emph}
\newcommand{\n}{\textnormal}
\newcommand{\m}{\mathrm}
\newcommand{\x}[1]{#1\index{#1}}
% .  ___  ___   ___        ___  ___   ___                   ___ 
% . `._|=|   |=|_.'   .'| `._|=|   |=|_.'   .'|        .'|=|_.' 
% .      |   |      .'  |      |   |      .'  |      .'  |  ___ 
% .      |   |      |   |      |   |      |   |      |   |=|_.' 
% .      `.  |      |   |      `.  |      |   |  ___ |   |  ___ 
% .        `.|      |___|        `.|      |___|=|_.' |___|=|_.' 
% .                                                            
\begin{document}
\begin{titlepage}
  \onecolumn
  \centering
  \large
  a\\
  \vspace{.5cm}
  {\Large \textsc{ Projektarbeit / Student Project}}\\
  \vspace{1cm}
  {\Huge \textsc{ Dual Channel Single Molecule Localisation Microscopy}}\\
  \vspace{1cm}
  concluded at the\\
  \vspace{.5cm}
  {\Large \textsc{Technische Universit\"at (Tu) Wien}}\\
  \vspace{.5cm}
  advised by\\
  \vspace{.5cm}
  {\Large \textsc{Lukas Velas}}\\
  \vspace{.5cm}
  of\\
  \vspace{.5cm}
  {\Large \textsc{Moritz Siegel}}\\
  \vfill
  \includegraphics[scale=.5]{npc/npc256.png}\\
  \vfill
  Vienna\\
  \today\\
  \vspace{.5cm}
  \small{\href{mailto:moritz.siegel@tuwien.ac.at}{moritz.siegel@tuwien.ac.at}}\\
  \small{\url{https://github.com/imrahilias/biophysics}}\\
\end{titlepage}
% .                    _    ___   ___  ___  ___   ___        __                     ___  ___  ___   ___ 
% .   .'|=|`.     .'|=| `. |   |=|_.' `._|=|   |=|_.'   .'|=|  |   .'|=|`.     .'|=|_.' `._|=|   |=|_.' 
% . .'  | |  `. .'  | | .' `.  |           |   |      .'  | |  | .'  | |  `. .'  |           |   |      
% . |   |=|   | |   |=|'.    `.|=|`.       |   |      |   |=|.'  |   |=|   | |   |           |   |      
% . |   | |   | |   | |  |  ___  |  `.     `.  |      |   |  |`. |   | |   | `.  |  ___      `.  |      
% . |___| |___| |___|=|_.'  `._|=|___|       `.|      |___|  |_| |___| |___|   `.|=|_.'        `.|      
% .
% \clearpage \onecolumn \chapter*{Abstract}
% asdf
% 
% \vfill
% 
% \section*{Keywords}
% asdf\\
% .  ___  ___   ___                    ___ 
% . `._|=|   |=|_.'   .'|=|`.     .'|=|_.' 
% .      |   |      .'  | |  `. .'  |      
% .      |   |      |   | |   | |   |      
% .      `.  |      `.  | |  .' `.  |  ___ 
% .        `.|        `.|=|.'     `.|=|_.' 
% .                                        
\clearpage \tableofcontents
% \clearpage \listoftodos % conflict: comment out \listoftodos when externalizing tikz, or use "\tikzexternalize[optimize=false"
% .              ___   ___  ___   ___        __              
% .   .'|   .'| |   | `._|=|   |=|_.'   .'|=|  |   .'|=|`.   
% . .'  | .'  |\|   |      |   |      .'  | |  | .'  | |  `. 
% . |   | |   | |   |      |   |      |   |=|.'  |   | |   | 
% . |   | |   | |  .'      `.  |      |   |  |`. `.  | |  .' 
% . |___| |___| |.'          `.|      |___|  |_|   `.|=|.'   
% .
\clearpage\chapter{Introduction}

\t{we want two color dyed SMLM data in sync, how to get there?}

Single Molecule Localisation Microscopy (SMLM) is a technique of
fitting a full Point Spread Functions (PSF) to a stack of images
containing reasonably spaced fluorescence signals.\\

To be able to accurately estimate the 3 dimensional location of the
fluorescent molecule, the PSF must be known quite well. Simply put: If
one knows the shape of a point source in varying degrees of defocus,
one can guess the defocus and thus the z coordinate of the
fluorescence molecule.\\



\section{Flouro}

\t{Flouro}


% .                     ___  ___  ___   ___                                      ___   ___ 
% .   .'|\/|`.     .'|=|_.' `._|=|   |=|_.'   .'| |`.     .'|=|`.     .'|=|`.   |   |=|_.' 
% . .'  |  |  `. .'  |  ___      |   |      .'  | |  `. .'  | |  `. .'  | |  `. `.  |      
% . |   |  |   | |   |=|_.'      |   |      |   |=|   | |   | |   | |   | |   |   `.|=|`.  
% . |   |  |   | |   |  ___      `.  |      |   | |   | `.  | |  .' |   | |  .'  ___  |  `.
% . |___|  |___| |___|=|_.'        `.|      |___| |___|   `.|=|.'   |___|=|.'    `._|=|___|
% .                                                                                     
\clearpage\chapter{Methods}


\section{SMLM}

\t{SMLM}


\section{TIRF}

\t{TIRF}


\section{dSTORM}
\t{dSTORM}

\subsection{Gloxy Buffer}

Single channel SMLM may employ the same buffer for both excitation
wavelengths, in our case at \SI{645}{\nm} (red) respective at
\SI{488}{\nm} (blue). After its central ingredients glucose and
oxidase, the buffer we used throughout this paper for all single
channel measurements unless noted otherwise is called Gloxy buffer:

\subsubsection{Gloxy buffer concentration}
\begin{itemize}
\item 50 \si{\milli\mol} $\beta$-MercaptoEthylamine hydrochloride (MEA, Sigma-Aldrich).
\item 10~vol\% of a \SI{250}{\g\per\L} solution of glucose.
\item \SI{0.5}{\mg\per\ml} glucose oxidase.
\item \SI{40}{\mg\per\ml} catalase (Sigma-Aldrich).
\item in PBS, pH 7.6 .
\end{itemize}

\subsection{OxEA Buffer}

Dual channel Fluorescence microscopy poses novel challenges to find a
proper dSTORM buffer, that works for both excitation
wavelengths---thus two distinct fluorophores AF647 and AF488. The
buffer composition we used is based on \t{cit}, and called OxEA after its main ingredients OxyFlour and ($\beta$-Mercapto)Ethylamine:

\subsubsection{OxEA buffer concentration}
\begin{itemize}
\item 50 \si{\milli\mol} $\beta$-MercaptoEthylamine hydrochloride (MEA, Sigma-Aldrich).
\item 3~vol\% OxyFlourTM (Oxyrase Inc., Mansfield, Ohio, U.S.A.).
\item 20~vol\% of \todo{60\%} sodium DL-lactate solution (L1375, Sigma-Aldrich).
\item in PBS, pH adjusted to 8â€“8.5 with NaOH.
\end{itemize}

\subsubsection{OxEA buffer protocol}

For about 1~\si{\milli\liter} of OxEA buffer we used the amounts shown
in Table~\ref{t:oxea}, to obtain above listed concentrations.

\begin{table}[!htb]
  \caption{Ingredients used for preparation of OxEA buffer for dual
    channel dSTORM buffer.} \label{t:oxea}
  \begin{tabularx}{.5\textwidth}{l X l r}
    \hhline{====}
    Order & Ingredient & Store & Vol / \si{\micro\liter} \\
    \hline
    1 & Ultra pure H$_2$O & & 600 \\
    2 & \SI{10}{\Molar} NaOH & & 20 \\
    3 & 10$\times$ PBS & & 100 \\
    4 & 60\% DL-lactate & fridge & 200 \\
    5 & \SI{1}{\Molar} MEA & freezer & 50 \\
    6 & OxyFluor & freezer & 30 \\
    \hhline{====}
  \end{tabularx}
\end{table}

\subsubsection{pH}

The pH of the OxEA buffer is checked using both broad range pH testing
strips, and a digital pH meter, to be between pH~7 and pH~8.



\section{PSF}

\t{PSF}


\section{Zernike}

\t{zern}


\section{Dual Channel Transforms}

\t{transform}




% . 
% .        __         ___  ___   ___  ___                    ___  ___   ___  ___   ___ 
% .   .'|=|  |   .'|=|_.' |   |=|_.' |   | |`.     .'|      `._|=|   |=|_.' |   |=|_.' 
% . .'  | |  | .'  |  ___ `.  |      |   | |  `. .'  |           |   |      `.  |      
% . |   |=|.'  |   |=|_.'   `.|=|`.  |   | |   | |   |           |   |        `.|=|`.  
% . |   |  |`. |   |  ___  ___  |  `.`.  | |   | |   |  ___      `.  |       ___  |  `.
% . |___|  |_| |___|=|_.'  `._|=|___|  `.|=|___| |___|=|_.'        `.|       `._|=|___|
% .                           
\clearpage\chapter{Results}


\section{Flouro}

\t{sample image}


\subsection{dSTORM}

\t{2d npc images}


\section{Single Molecule Localisation}

It is possible to use different excitations to simultaneously measure
different fluorescence markers, but for that the Point Spread
Functions (PSF) has to known for each wavelength. So the PSFs are
estimated both for red and blue laser light, with the Phase Retrieval
program by [Jesacher et al 21?]; each on a stack of 50000~STORM images
of \SI{100}{\nm} \t{100nm?} beads stained with fluorescence dyes for
both red (\SI{645}{\nm}) and blue (\SI{488}{\nm}) laser light.\\


\subsection{Correction Collar}

To further complicate things, the new Olympus 1.5~NA objective comes
with a Correction Collar to compensate for aberrations---which
naturally vary slightly for both color channels. In order to find the
best Correction Collar setting of the Olympus 1.5~NA objective for
SMLM, the Point Point Spread Functions (PSF) is computed for each of
the three settings of the correction collar $\{0.13,0.17,0.19\}$;
using the program by [Jesacher et al 21?].\\


\subsection{Zernike Modes}

The Zernike modes of the PSF are shown for each of the three
correction collar settings $\{0.13,0.17,0.19\}$, each for blue channel
respective red channel in Figure~\ref{f:zernblue} respective
Figure~\ref{f:zernred}.\\

For convenience the same results are additionally shown grouped by the
the three correction collar settings $\{0.13,0.17,0.19\}$, now for
both red and blue channel in Figure~\ref{f:zern013},
Figure~\ref{f:zern017} and Figure~\ref{f:zern019}.\\

% \begin{figure*}[!t]
%   \begin{tikzpicture}
%     \begin{axis}[
%       %       enlargelimits=false,
%       smooth,
%       grid=both,
%       grid style=dashed,
%       xlabel={Zernike mode number},
%       %       xticklabels={,,},
%       ylabel={Aberration / au},
%       %       grid=major,
%       legend entries={0.13 X,0.13 X,0.13 X},
%       %       legend pos = north west,
%       ybar = 1pt,% configures `bar shift'
%       bar width = 1pt,
%       %       nodes near coords,
%       %       point meta = y*1e2, % the displayed number
%       xmin = 0,
%       xmax = 57,
%       ymin = -0.1,
%       ymax = 0.1,
%       ]
%       \addplot+ [ ybar, color=teal ]
%       table [ x=modes, y=0.13blue, col sep=comma ] {crlb/Zernikes.csv};
%       \addplot+ [ ybar, color=orange ]
%       table [ x=modes, y=0.17blue, col sep=comma ] {crlb/Zernikes.csv};
%       \addplot+ [ ybar, color=purple ]
%       table [ x=modes, y=0.19blue, col sep=comma ] {crlb/Zernikes.csv};
%     \end{axis}
%   \end{tikzpicture}
%   \caption{ asdf }
%   \label{f:axes}
% \end{figure*}


\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={Zernike mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.13 blue, 0.17 blue, 0.19 blue},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=teal ]
      table [ y=modes, x=0.13blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=orange ]
      table [ y=modes, x=0.17blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.19blue, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Blue channel Zernike modes $\{1\dots37,56\}$ versus
    aberrations of PSF model via phase retrieval, for all three
    correction collar settings (0.13, 0.17, 0.19).}
  \label{f:zernblue}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={Zernike mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.13 red, 0.17 red, 0.19 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=teal ]
      table [ y=modes, x=0.13red, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=orange ]
      table [ y=modes, x=0.17red, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.19red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red channel Zernike modes $\{1\dots37,56\}$ versus
    aberrations of PSF model via phase retrieval, for all three
    correction collar settings (0.13, 0.17, 0.19).}
  \label{f:zernred}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={Zernike mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.13 blue, 0.13 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=cyan ]
      table [ y=modes, x=0.13blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.13red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red and blue channel Zernike modes $\{1\dots37,56\}$
    versus aberrations of PSF model via phase retrieval, for
    correction collar setting of 0.13.}
  \label{f:zern013}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={Zernike mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.17 blue, 0.17 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=cyan ]
      table [ y=modes, x=0.17blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.17red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red and blue channel Zernike modes $\{1\dots37,56\}$
    versus aberrations of PSF model via phase retrieval, for
    correction collar setting of 0.17.}
  \label{f:zern017}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={Zernike mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.19 blue, 0.19 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=cyan ]
      table [ y=modes, x=0.19blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.19red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red and blue channel Zernike modes $\{1\dots37,56\}$
    versus aberrations of PSF model via phase retrieval, for
    correction collar setting of 0.19.}
  \label{f:zern019}
\end{figure*}


\clearpage\subsection{Cramer Rao Lower Bound}

In order to find the best Correction Collar setting of the Olympus
1.5~NA objective for SMLM, the Cramer Rao Lower Bound (CRLB) is
computed using the program by [Jesacher et al 21?], with prior
estimated Point Spread Functions (PSF) via phase retrieval [Jesacher
et al 21?].\\

All CRLBs are computed at a defocus position of -500~nm, in steps of
5~nm from 0 to 500 nm. For all Estimations we assume identical
arbitrary signal strength (2500) respective background (100).\\

The Estimated Cramer Rao Lower Bound for different correction Collar
settings (variing linestyles for 0.13, 0.17, 0.19) of the Olympus
1.5~NA objective; for X, Y and Z axis (top, middle, and bottom); for
both red and blue channel (colors) is shown in
Figure~\ref{f:all}.\\

Additionally plots grouped by X, Y and Z axis are shown in
Figure~\ref{f:axes}, as well as grouped by different correction Collar
settings in Figure~\ref{f:collar}.\\

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      % xmin=0,
      % xmax=10,
      ymin=0,
      ymax=60,
      % cycle list name = exotic,
      % cycle list name=linestyles*,
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xlabel={Z Position / \n{nm}},
      ylabel={X,Y,Z Cramer Rao Lower Bound / \n{nm}},
      grid=major,
      legend entries={X 0.13 blue, X 0.17 blue, X 0.19 blue, X 0.13 red, X 0.17 red, X 0.19 red,
        Y 0.13 blue, Y 0.17 blue, Y 0.19 blue, Y 0.13 red, Y 0.17 red, Y 0.19 red,
        Z 0.13 blue, Z 0.17 blue, Z 0.19 blue, Z 0.13 red, Z 0.17 red, Z 0.19 red },
      legend pos = north west,
      ]
      \addplot[ color=cyan ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_013_blue2.csv };
      \addplot[color=cyan, dotted, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_017_blue2.csv};
      \addplot[color=cyan, densely dotted, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_019_blue2.csv};
      \addplot[color=purple, loosely dotted, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_013_red2.csv};
      \addplot[color=purple, dashed, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_017_red2.csv};
      \addplot[color=purple, densely dashed, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_019_red2.csv};
      \addplot[color=cyan, loosely dashed, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_013_blue2.csv };
      \addplot[color=cyan, dashdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_017_blue2.csv};
      \addplot[color=cyan,densely dashdotted, very thick  ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_019_blue2.csv};
      \addplot[color=purple, loosely dashdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_013_red2.csv};
      \addplot[color=purple, dashdotdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_017_red2.csv};
      \addplot[color=purple, densely dashdotdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_019_red2.csv};
      \addplot[color=cyan, loosely dashdotdotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_013_blue2.csv };
      \addplot[color=cyan ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_017_blue2.csv};
      \addplot[color=cyan, dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_019_blue2.csv};
      \addplot[color=purple, densely dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_013_red2.csv};
      \addplot[color=purple, loosely dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_017_red2.csv};
      \addplot[color=purple, loosely dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_019_red2.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{Estimated Cramer Rao Lower Bound for different correction
    Collar settings (variing linestyles for 0.13, 0.17, 0.19) of the
    Olympus 1.5~NA objective; for X, Y and Z axis (top, middle, and
    bottom); for both red and blue channel (colors).}
  \label{f:all}
\end{figure*}
~ % dirty hack

% 
\begin{figure}[!t]
  \begin{subfigure}[t!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={Cramer Rao Lower Bound / \n{nm}},
        grid=major,
        legend entries={0.13 X,0.13 X,0.13 X},
        % legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={Cramer Rao Lower Bound / \n{nm}},
        grid=major,
        legend entries={0.17 Y,0.17 Y,0.17 Y},
        % legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        xlabel={Z Position / \n{nm}},
        ylabel={Cramer Rao Lower Bound / \n{nm}},
        grid=major,
        legend entries={0.19 Z,0.19 Z,0.19 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \caption{ Estimated Cramer Rao Lower Bound for different correction
    Collar settings (teal: 0.13, orange: 0.17, purple: 0.19) of the
    Olympus 1.5~NA objective; grouped by X, Y and Z axis (top, middle,
    and bottom).}
  \label{f:axes}
\end{figure}
% 
\begin{figure}[!t]
  \begin{subfigure}[t!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,        
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={Cramer Rao Lower Bound / \n{nm}},
        grid=major,
        legend entries={0.13 X,0.13 Y,0.13 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_013_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_013_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={Cramer Rao Lower Bound / \n{nm}},
        grid=major,
        legend entries={0.17 X,0.17 Y,0.17 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_017_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_017_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        xlabel={Z Position / \n{nm}},
        ylabel={Cramer Rao Lower Bound / \n{nm}},
        grid=major,
        legend entries={0.19 X,0.19 Y,0.19 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_019_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_019_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \caption{ Estimated Cramer Rao Lower Bound for X, Y and Z axis
    (teal, orange and purple lines); grouped by different correction
    Collar settings (top: 0.13, middle: 0.17, bottom: 0.19) of the
    Olympus 1.5~NA objective.}
  \label{f:collar}
\end{figure}


\clearpage\section{Dual Channel: Simulation}

\t{Dual Channel: Simulation}

\begin{figure*}[!t]
  \vspace{-3em}
  \rotatebox{90}{\b{Shift}}
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \b{Rigid Recovery}
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        % label shift = -10pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_rigid_rec_shift/q.dat};
        \addplot3[magenta, only marks, mark=x] table {sim_rigid_rec_shift/pr.dat};
        \addplot3[magenta, mark=x] table {sim_rigid_rec_shift/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_rigid_rec_shift/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  ~
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \b{Affine Recovery}
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        % label shift = -10pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_affine_rec_shift/q.dat};
        \addplot3[magenta, only marks, mark=x] table {sim_affine_rec_shift/pr.dat};
        \addplot3[magenta, mark=x] table {sim_affine_rec_shift/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_affine_rec_shift/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \\
  \rotatebox{90}{\b{Rigid}}
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -15pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_rigid_rec_rigid/q.dat};
        \addplot3[magenta, only marks, mark=x] table {sim_rigid_rec_rigid/pr.dat};
        \addplot3[magenta, mark=x] table {sim_rigid_rec_rigid/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_rigid_rec_rigid/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  ~
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -15pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_affine_rec_rigid/q.dat};
        \addplot3[magenta, mark=x] table {sim_affine_rec_rigid/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_affine_rec_rigid/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \\
  \rotatebox{90}{\b{Affine}}
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -5pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-2,
        xmax=2,
        ymin=-2,
        ymax=2,
        grid=major
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_rigid_rec_affine/q.dat};
        \addplot3[magenta, mark=x] table {sim_rigid_rec_affine/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_rigid_rec_affine/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  ~
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -5pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-2,
        xmax=2,
        ymin=-2,
        ymax=2,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_affine_rec_affine/q.dat};
        \addplot3[magenta, mark=x] table {sim_affine_rec_affine/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_affine_rec_affine/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  % 
  \caption{Demonstration of the recovery of rigid (left) respective
    affine (right) transformations, via recovering localisations of
    simulated two channel SMLM data; transformation (magenta) from red
    channel (violet) to blue channel (cyan); for the use cases of
    translation (top), rigid transformation (middle) and affine
    transformation (bottom). Obviously a rigid transformation may not
    correctly reconstruct an affine transformed data set (bottom
    left).}
  \label{f:transim}
\end{figure*}


\clearpage\section{Dual Channel: NPC}

\t{Dual Channel: NPC}

\begin{figure*}[!t]
  \vspace{-5em}
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      width=0.7\textwidth,
      height=0.7\textwidth,
      name=ax1,
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xlabel={X Position / \n{nm}},
      ylabel={Y Position / \n{nm}},
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xmin=0.5e4,
      xmax=0.85e4,
      ymin=0.5e4,
      ymax=0.851e4,
      grid=major,
      thick,
      mark size=8pt,
      ]
      \addplot[cyan, only marks, mark=x] table {npc_rigid/centroid_blue.mat};
      \addplot[violet, only marks, mark=+] table {npc_rigid/centroid_red.mat};
      \addplot[magenta, only marks, mark=o] table {npc_rigid/centroid_blue_transformed.mat};
    \end{axis}
    \begin{axis}[
      width=0.7\textwidth,
      height=0.7\textwidth,
      name=ax2,
      % place second axis relative to first one anchor is south west
      at={($(ax1.north west)+(0,1.5cm)$)},
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xlabel={X Position / \n{nm}},
      ylabel={Y Position / \n{nm}},
      xmin=0,
      xmax=2e4,
      ymin=0,
      ymax=2e4,
      grid=major,
      thick,
      mark size=8pt,
      legend entries={blue channel, red channel, rigid transformation},
      ]
      \addplot[cyan, only marks, mark=x] table {npc_rigid/centroid_blue.mat};
      \addplot[violet, only marks, mark=+] table {npc_rigid/centroid_red.mat};
      \addplot[magenta, only marks, mark=o] table {npc_rigid/centroid_blue_transformed.mat};
      % define coordinates at bottom left and top left of rectangle
      \coordinate (c1) at (axis cs:0.5e4,0.5e4);
      \coordinate (c2) at (axis cs:0.5e4,0.85e4);
      \coordinate (c3) at (axis cs:0.85e4,0.85e4);
      % draw a rectangle
      \draw (c1) rectangle (axis cs:0.85e4,0.85e4);
    \end{axis}
    % draw dashed lines from rectangle in first axis to corners of second
    \draw [dashed] (c2) -- (ax1.north west);
    \draw [dashed] (c3) -- (ax1.north east);
  \end{tikzpicture}
  \caption{Demonstration of a rigid transformation of the
    localisations (magenta $\circ$) from blue channel (blue $\times$)
    to red channel (violet $+$); the transformed blue channel
    localisations mostly align well with the red channel
    localisations.}
  \label{f:npc_rigid}
\end{figure*}


\clearpage\section{SMLM Analysis}\label{s:r:ana}

Applying the SMLM described in Section~\t{sec} for the stack of
microscopy images, one obtains a list of localisations comprised of
position (\tt{x,y,z}), photon count (\tt{n}), and a fit parameter
(\tt{fit}). Where the \tt{sans serif} typeset letters refer to the
variables in the code listed in this chapter.

In this section I want to describe our data analysis pipeline, in
order to cut down the massive amount of initial localisations---in our
example case over 130k---to distill it to the most meaningful
conclusions.

As a proof of work we used NPCs as sort of a well defined biological
test target. As these are used frequently for the purpose of
validating a new method, it would be nice to quickly evaluate of
\e{how good are the NPCs resolved}. The Section \t{sec} is thus
dedicated to find some metric for \e{best resolved} NPCs.

This analysis is performed in \e{Python}, and is freely available in
my Git repository \t{git}; both as a plain python file (.py) as well
as in the format of a \e{Jupyter Notebook} (.ipynb).

For the sake of readability we omit the code sections generating the
shown plots, as they are mostly redundant. Of course the full code is
available online.

\t{npc image}

\t{appendix}

% \usemintedstyle{
%   manni,
%   linenos = true,
%   frame = single,
% }

\subsection{Import}

Here we import the used packages and the data file we obtain from
running the SMLM algorithm.

% \begin{minted}{python}
%   #@markdown ##import core
%   import pandas as pd
%   import matplotlib.pyplot as plt
%   import numpy as np
%   import matplotlib as mpl
%   from mpl_toolkits.mplot3d import Axes3D
%   import scipy.io
%   from sklearn.cluster import DBSCAN
%   from sklearn import metrics
%   from sklearn.datasets import make_blobs
%   from sklearn.preprocessing import StandardScaler

%   #@markdown ##import jupyter
%   #%matplotlib ipympl
%   #%matplotlib widget
%   #%matplotlib interactive
%   % matplotlib inline
%   import trackpy
%   #import sdt
%   #from sdt import io, chromatic, multicolor, brightness
  
%   ## local
%   wd = 'data/210422_npc_red_defocus/'
%   data = pd.read_csv( wd + 'cell1_tr1000_def500.csv',
%   header = None,
%   names=["x", "y", "z", "n", "bg","fit","id","frame"] )
% \end{minted}

\subsection{Drift Correction}

The \e{drift} of the setup over time can be estimated using
\e{ImageJ}, and is then imported as \tt{drift} \t{drift}. In the
following block the drift correction is applied to all the 130k
localisations, shown in Figure~\ref{f:2_drift} as 3d plot of all the
initial 370k drift corrected localisations.

% \begin{minted}{python}
%   #@markdown ## import & scale drift
%   #@markdown > set **magnification** via factor in drift.

%   drift = pd.read_csv( wd + 'day2_cell1_driftValues.csv')

%   drift['Y2']=drift['Y2']*146.6
%   drift['Y3']=drift['Y3']*146.6
%   drift['X2']=np.round(drift['X2'])
%   drift['X3']=np.round(drift['X3'])

%   #@markdown ## apply drift correction

%   for i in range(len(drift)-1):
%   fr=data[(data['frame']>=drift['X2'].iloc[i]) &
%   (data['frame']<drift['X2'].iloc[i+1])]
%   fr['y']=fr['y']-drift['Y2'].iloc[i]
%   fr['x']=fr['x']-drift['Y3'].iloc[i]
%   data[(data['frame']>=drift['X2'].iloc[i]) &
%   (data['frame']<drift['X2'].iloc[i+1])]=fr
% \end{minted}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{2_drift.png}
  \caption{3d plot of all 370148 drift corrected localisations, color
    coded by photon count.}
  \label{f:2_drift}
\end{figure}


\subsection{Photon Counts}

As a preliminary step it might prove useful to look at the photon
count statistics, shown in Figure~\ref{f:3_photons}. Here we can easily
see what the supposed intensity of a single molecule is; the peak, in
our case about 2000. Those localisations below may be considered
noise, those far above are probably overlapping or stacked molecules,
so their intensities add up.

% \begin{minted}{python}
%   #@markdown ## Check: photon counts
%   #@markdown > set `max_photons` accordingly (default: 10000).
%   max_photons = 10000 #@param {type:"slider", min:0, max:40000, step:1000}
  
%   fig = plt.figure()
%   plt.hist( data['n'], bins=50, range=( 0, max_photons ) )
% \end{minted}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{3_photons.png}
  \caption{histogram of the photon count for the localisations.}
  \label{f:3_photons}
\end{figure}


\subsection{Filter}

In this first filter we limit the dataset to the more meaningful
points; like those with intensities between 2k and 7k. Also since we
de-focussed for \SI{500}{\n\m}, only those \tt{z} values between 0 and 499 can
be considered realistic. Here 0 means directly attached to the glass
substrate, so negative values would be \e{inside} the glass substrate;
and thus need to be discarded as unplausible. The dataset could be
filtered by \tt{min\_fit}, but to our findings this does not contribute
much.

Figure~\ref{f:4_filter} shows a 3d plot of the remaining 154k
localisations after we apply the filter, thus effectively shrinking
down our exemplary data set by about 40\%.

% \begin{minted}{python}
%   #@markdown ## filter
%   #@markdown > set `min_photons` and `max_photons` accordingly (default: 2000 < photons < 7000).\
%   #@markdown > set `min_z` and `max_z` accordingly (default: 0 < z < 499).\
%   #@markdown > set `min_fit` accordingly (default: 6e6).
%   min_photons = 2000 #@param {type:"slider", min:0, max:40000, step:1000}
%   max_photons = 7000 #@param {type:"slider", min:0, max:40000, step:1000}
%   min_z = 0 #@param {type:"slider", min:0, max:500, step:1}
%   max_z = 384 #@param {type:"slider", min:0, max:500, step:1}
%   min_fit = 7192000 #@param {type:"slider", min:0, max:1e7, step:1000}
  
%   fdata = data[ ( data['n'] > min_photons ) &
%   ( data['n'] < max_photons ) & 
%   ( data['z'] > min_z ) &
%   ( data['z'] < max_z ) &
%   ( data['fit'] < min_fit ) ]
% \end{minted}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{4_filter.png}
  \caption{3d plot of all 154237 filtered localisations, color coded
    by photon count.}
  \label{f:4_filter}
\end{figure}


\subsection{Track Particles}

The 50k frames we analyse here are taken with exposure of
\SI{20}{\m\s}, and \SI{10}{\m\s} between consecutive
exposures. Depending on the laser intensity and the buffer composition
the bright state has a specific half-life. This leads to one exemplary
molecule being \e{on} for some \SI{30}{\m\s} (one frame) while some
other is on for \SI{60}{\m\s}; and so appears in two consecutive
frames. Since the molecule in those two frames essentially is the
same, we can \e{track} it over time: effectively averaging the
location if present in multiple frames, thus reducing the amount of
localisations while at the same time increasing their precision.

The parameters \tt{sr} denotes the \e{search range}, how far apart two
consecutive localisations are still considered \e{one} particle, this
has to be adjusted based on the physical setup considering vibrations
and the like.

Figure~\ref{f:5_tracking} shows a 3d plot of the remaining 98k
localisations, after we track the particles. So the tracking step
further shrinks down our exemplary data set by about 60\%.

% \begin{minted}{python}
%   #@markdown ## track all in x,y
%   #@markdown > set `sr` to wanted search range (default: 50).\
%   #@markdown > set `mem` to wanted memory (default: 10).
%   sr = 50 #@param {type:"slider", min:0, max:100, step:1}
%   mem = 10 #@param {type:"slider", min:0, max:100, step:1}
  
%   linkedxy = trackpy.link_df( fdata,
%   pos_columns = ["x","y","z"],
%   search_range = sr,
%   memory = mem )
  
%   particles = linkedxy.groupby( "particle" ).aggregate( np.mean )
%   std_pos = linkedxy.groupby( "particle" ).aggregate( 'std' )
%   particles["length"] = linkedxy.groupby( "particle" ).apply( len )
%   particles["z_std"] = std_pos['z'].copy()
%   particles["x_std"] = std_pos['x'].copy()
%   particles["y_std"] = std_pos['y'].copy()
% \end{minted}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{5_tracking.png}
  \caption{3d plot of all 98456 filtered localisations, color coded by
    photon count.}
  \label{f:5_tracking}
\end{figure}


\section{SMLM Analysis: NPC}\label{s:r:ananpc}

We use NPCs as a test target for our method, thus we have some
additional knowledge, like the geometry of each individual NPC: they
comprise two stacked \t{tori}, each about \SI{150}{\n\m} diameter (in
x,y direction), and \SI{150}{\n\m} apart (in z direction).

Now we can group our dataset with close to 100 thousand localisations
to clusters of roughly this size in x,y (set \tt{dim=2}). Note that
for the sake of completeness, we include the possibility of clustering
in 3d to spheres in x,y,z (set \tt{dim=3}), but mind that x,y and z
precision most often greatly varies (see Section~\t{sec}).

The parameter \tt{min\_samples} denotes the minimum amount of
constituents a cluster must have to be considered such.

Figure~\ref{f:5_tracking} shows a 3d plot of the localisations of 658
identified clusters, omitting all the other 35489 localisations as
noise. So the clustering step further shrinks down our exemplary data
set by about 30\%.


\subsection{Clustering}

% \begin{minted}{python}
%   #@markdown ## compute dbscan
%   #@markdown > set `dim = 2` for clustering in x and y (default:).\
%   #@markdown > set `dim = 3` for experimental clustering in 3d; be aware that x,z and y precision probably vary!\
%   #@markdown > set `eps` (default: 200).\
%   #@markdown > set `min_samples` (default: 10).
%   dim = "2" #@param [2, 3]
%   eps = 100 #@param {type:"slider", min:0, max:500, step:10}
%   min_samples = 50 #@param {type:"slider", min:1, max:100, step:1}

%   alocalisations = localisations.to_numpy()
%   alocalisations[ :, 0:2 ]

%   db = DBSCAN( eps, min_samples ).fit( alocalisations[ :, 0:int( dim ) ] )
%   core_samples_mask = np.zeros_like( db.labels_, dtype=bool )
%   core_samples_mask[ db.core_sample_indices_ ] = True
%   labels = db.labels_
%   localisations[ "cluster" ] = labels

%   # count clusters (ignore noise if present)
%   n_clusters_ = len( set( labels ) ) - ( 1 if -1 in labels else 0 )
%   n_noise_ = list( labels ).count( -1 )

%   #print('Estimated number of clusters: %d' % n_clusters_)
%   #print('Estimated number of noise points: %d' % n_noise_)

%   nlocalisations = localisations.loc[ localisations['cluster'] == -1 ]
%   clocalisations = localisations.loc[ localisations['cluster'] != -1 ]
% \end{minted}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{6_clustering.png}
  \caption{3d plot of the localisations of the 658 identified clusters
    (omitting 35489 localisations as noise, due to not belonging to a
    cluster), color coded by photon count.}
  \label{f:6_clustering}
\end{figure}


\subsection{Cluster Analysis}

For all the localisations within each of these identified clusters, we
now derive the centroid position (\tt{xmean,ymean,zmean}), with
standard derivation (\tt{xvar,yvar,zvar}). This enables the
classification of the within-cluster distribution of localisations,
alas how well they represent the anticipated NPC geometry.

To obtain this \e{quality}, we compose both the quantity
\tt{ringness}, denoting how well the cluster shapes a ring in x,y
direction; as well as the quantity \tt{twofold}, denoting how well the
cluster shapes two stacked tori in z direction, basically forming a
camel-curve in z direction. To break this down to one scalar each, we
compute the root mean square (RMS) of the deviations of each
localisations radius from the cluster centre (in x,y direction) from
the known NPC radius (Lines~20--24). The quantity \tt{twofold} is
similarly comprised of a (RMS) deviation of each localisations z value
from the cluster centre (in z direction) from the known NPC
height. The mentioned parameters are thus called \tt{npc\_radius},
respective \tt{npc\_height}.

Figure~\ref{f:7_filtered_clusters} shows a broad overview of the
location of the cluster centres (not the localisations within), color
coded by photon count. This should be considered more of a short
sanity check than a profound analysis.

% \begin{minted}{python}
%   #@markdown ## analyse clusters
%   #@markdown > set `npc_radius` to NPC radius /nm (default: 50).\
%   #@markdown > set `npc_radius` to NPC haight /nm (default: 150).
%   npc_radius = 50 #@param {type:"slider", min:0, max:500, step:1}
%   npc_height = 25 #@param {type:"slider", min:0, max:500, step:1}

%   clabels = set(labels)
%   cnames = [ "counts", "xmean", "ymean", "zmean", "nmean", "xvar", "yvar", "zvar",
%   "nvar", "label", "ringness", "twofold" ]
%   clusters = pd.DataFrame( index = clabels, columns = cnames, dtype="float64" )
%   clusters[ "label" ] = clabels

%   for k in clabels:
%   tmp = localisations.loc[ localisations['cluster'] == k ]
%   clusters.loc[ k, "counts" ] = len( tmp )
%   for label in [ "x", "y", "z", "n" ]:
%   clusters.loc[ k, label+"mean"  ] = np.mean( tmp.loc[ :, label ] )
%   clusters.loc[ k, label+"var"  ] = np.var( tmp.loc[ :, label ] )

%   ## xy: radius (distance to centroid)
%   rad = np.sqrt( ( tmp.loc[ :, "x" ] - clusters.loc[ k, "xmean" ] )**2 + 
%   ( tmp.loc[ :, "y" ] - clusters.loc[ k, "ymean" ] )**2 )
%   ## xy: radius rms deviation from NPC radius
%   clusters.loc[ k, "ringness"  ] = np.sqrt( sum( ( rad - npc_radius )**2 ) )

%   ## z: radius (distance to centroid)
%   rad = abs( tmp.loc[ :, "z" ] - clusters.loc[ k, "zmean" ] )
%   ## z: radius rms deviation from NPC radius
%   clusters.loc[ k, "twofold"  ] = np.sqrt( sum( ( rad - npc_height )**2 ) )

%   #@markdown ## filter clusters
%   #@markdown > set `count_threshold` to min elements (counts) in cluster (default: 30)\
%   #@markdown > set `diameter_threshold` to max x,y (radius) deviation of cluster from NPC diameter (default: 200)\
%   #@markdown > set `twofold_threshold` to max z (radius) deviation of cluster from NPC height (default: 200)\
%   #@markdown > set `xyvar_threshold` to wanted x,y variance (default: 1e4)\
%   #@markdown > set `zvar_threshold` to wanted z variance (default: 1e4)
%   count_threshold = 100 #@param {type:"slider", min:0, max:200, step:1}
%   diameter_threshold = 500 #@param {type:"slider", min:0, max:500, step:10}
%   twofold_threshold = 1000 #@param {type:"slider", min:0, max:1000, step:10}
%   xyvar_threshold = 100000 #@param {type:"slider", min:0, max:1e5, step:1e3}
%   zvar_threshold = 100000 #@param {type:"slider", min:0, max:1e5, step:1e3}

%   fclusters = clusters[ ( clusters['counts'] < count_threshold ) &
%   ( clusters['ringness'] < diameter_threshold ) &
%   ( clusters['twofold'] < twofold_threshold ) &
%   ( clusters['xvar'] < xyvar_threshold ) & 
%   ( clusters['yvar'] < xyvar_threshold ) &
%   ( clusters['zvar'] < zvar_threshold ) ]
% \end{minted}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{7_filtered_clusters.png}
  \caption{3d plot of the positions of the 451 filtered clusters,
    color coded by photon count.}
  \label{f:7_filtered_clusters}
\end{figure}


\subsection{Select Clusters}

Now we possess all the information needed to evaluate the list of
clusters; for example to sort for the lets say 10 most \e{ringlike}
clusters. Or, by setting \tt{sort = 'ringness + twofold'}, we may find
the 10 \e{best} clusters in terms of both \tt{ringness} and
\tt{twofold}---weighted equally---which would comprise the 10
\e{overall best}, thus \e{most NPC like} clusters.

For sake of completeness we also include the x,y and z variances, even
if they do not comprise a very meaningful parameter in the particular
case due to the NPCs geometry.

Figure~\label{f:89_best_filtered_clusters} shows a 3d plot of the
localisations within the 10 \e{best} clusters, color coded by photon
count.

% \begin{minted}{python}
%   #@markdown ## select best clusters & plot localisations
%   #@markdown > set `show_clusters` to wanted number of best clusters (default: 100).\
%   #@markdown > set `sort` to sort the best clusters (default: ringness + twofold).
%   show_clusters = 10 #@param {type:"slider", min:0, max:1000, step:1}
%   sort = 'ringness + twofold' #@param [ "ringness + twofold", "twofold", "ringness", "xyvar" , "xvar" ]

%   if sort == "xvar": # sort by variance
%   sclusters = fclusters.sort_values( "xvar" )
%   elif sort == "xyvar": # sort by x and y variance using least squares
%   sclusters = fclusters.loc[
%   ( fclusters.xvar ** 2 + fclusters.yvar ** 2 ).sort_values().index ]
%   elif sort == "ringness": # sort by ringness (deviation to ringness)
%   sclusters = fclusters.sort_values( "ringness" )
%   elif sort == "twofold": # sort by ringness (deviation to ringness)
%   sclusters = fclusters.sort_values( "twofold" )
%   elif sort == "ringness + twofold": # sort by ringness (deviation to ringness)
%   sclusters = fclusters.loc[
%   ( fclusters.twofold ** 2 + fclusters.ringness ** 2 ).sort_values().index ]

%   show_clusters = min( show_clusters, len( sclusters ) )
%   selected_clusters = sclusters["label"].iloc[ 0:show_clusters ]

%   fig = plt.figure()
%   ax = fig.add_subplot( projection = '3d' )
%   for clus in selected_clusters:
%   flocalisations = localisations[ ( localisations['cluster'] == clus ) ]
%   ff = ax.scatter( flocalisations['x'],
%   flocalisations['y'],
%   flocalisations['z'],
%   s=1 ,c = flocalisations['n'] )
% \end{minted}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{8_best_filtered_clusters.png}
  % \includegraphics[width=0.5\textwidth]{9_best_filtered_clusters.png}
  \caption{3d plot of the localisations within the 10 \e{best}
    clusters, color coded by photon count.}
  % (top) respective color coded by cluster assignment (bottom)
  \label{f:89_best_filtered_clusters}
\end{figure}


\subsection{X,Y,Z Histograms}\label{s:r:xyzhist}

As a further sanity check, we plot the histograms for selected
clusters (\tt{plot\_cluster}), in x,y and z direction; to figure out
if the sorting did work effectively---thus the higher sorted clusters
are indeed \e{better} examples of NPCs.

Figure~\ref{f:10_xyz_best_filtered_clusters} shows exemplary
histograms of the x,y (right) respective z distribution (left) of the
localisations within the \e{best} cluster (top), the \e{worst}
(bottom) and one in between.

% \begin{minted}{python}
%   #@markdown ## Check: z distribution
%   #@markdown > set `plot_cluster` to wanted cluster (default: 0).
%   plot_cluster = 3  #@param {type:"slider", min:0, max:100, step:1}
%   plot_cluster = min( plot_cluster, len( sclusters ) -1 )

%   tmp = localisations.loc[ localisations['cluster'] == 
%   sclusters.loc[ sclusters.index[ plot_cluster ],
%   "label" ] ]

%   z = tmp.z - np.mean( tmp.z )

%   fig, axes = plt.subplots(2, 1, figsize=(4, 7) ) # figsize=(4, 12)

%   axes[0].hist( tmp.z - np.mean( tmp.z ) )
%   axes[0].set_xlabel('z / nm')
%   axes[0].set_ylabel('counts')
%   #axes[0].set_title( 'z' )

%   axes[1].hist( tmp.x - np.mean( tmp.x ) )
%   axes[1].hist( tmp.y - np.mean( tmp.y ) )
% \end{minted}

\begin{figure}[h!]
  \centering
  % \rotatebox{90}{\hspace{7em} cluster 1}
  cluster 1\\
  \includegraphics[width=0.5\textwidth]{10_histograms_1.png}\\
  % \rotatebox{90}{\hspace{7em} cluster 10}
  cluster 10\\
  \includegraphics[width=0.5\textwidth]{10_histograms_10.png}\\
  % \rotatebox{90}{\hspace{7em}cluster 450}
  cluster 450\\
  \includegraphics[width=0.5\textwidth]{10_histograms_450.png}
  \caption{histogram of the x,y (right) respective z distribution
    (left) of the localisations within the \e{best} cluster (top), the
    \e{worst} (bottom) and one in between.}
  \label{f:10_xyz_best_filtered_clusters}
\end{figure}


\twocolumn


% .                    ___   ___        ___  ___         ___   ___  ___   ___                          ___  
% .   .'|=|`.     .'| |   |=|_.'   .'|=|_.' |   | |`.   |   |=|_.' |   |=|_.'   .'|   .'|=|`.     .'| |   | 
% . .'  | |  `. .'  | `.  |      .'  |      |   | |  `. `.  |      `.  |      .'  | .'  | |  `. .'  |\|   | 
% . |   | |   | |   |   `.|=|`.  |   |      |   | |   |   `.|=|`.    `.|=|`.  |   | |   | |   | |   | |   | 
% . |   | |  .' |   |  ___  |  `.`.  |  ___ `.  | |   |  ___  |  `. ___  |  `.|   | `.  | |  .' |   | |  .' 
% . |___|=|.'   |___|  `._|=|___|  `.|=|_.'   `.|=|___|  `._|=|___| `._|=|___||___|   `.|=|.'   |___| |.'   
% .                   
\clearpage\chapter{Discussion}

\section{SMLM}


\subsection{Phase Retrieval}

The image stacks look ok, even if not all are perfectly
symmetrical--some errors are to be expected.\\

The estimated Zernike modes of the PSF are mostly plausible; based on
the modes and the order of magnitude.\\

This is further backed by the comparison of the results grouped by the
three correction collar settings $\{0.13,0.17,0.19\}$, in
Figure~\ref{f:zern013}, Figure~\ref{f:zern017} and
Figure~\ref{f:zern019}. It is quite obvious, that the results for both
red and blue channel are in the same order of magnitude---if not quite
similar---for most of the Zernike modes, as suspected by theory
\t{zern}.\\

Yet the phase Retrieval program gave the error \e{high residual error}
for both the red and the blue channel when using the correction collar
settings $\{0.17,0.19\}$, is this a serious problem?\\

how can we avoid it?


\subsection{Correction Collar}

Based on the Figures~\ref{f:axes} and Figure~\ref{f:collar}, and
considering the fact---that we are interested in moderately defocusing
(up to say 250~nm)---one might conclude, that the most preferable
setting for the correction collar is 0.13.\\

Yet the recommended setting for our microscope setup is 0.17! Which is
backed by Lukas, based on the PSF stacks: One would have guessed the
0.17 is more sensitive to z since it changes much more with different
z positions than 0.13.\\

Which is the one we should use?\\


\section{SMLM Analysis}

The analysis performed in Section~\ref{s:r:ana} is well suited to
greatly reduce the localisations, just by omitting unplausible data
and noise; in our example from initially 370k to below 100k, or to
about 26\%.


\section{SMLM Analysis: NPC}~\label{s:d:ananpc}

\subsection{Automation}
  
The fully automatic evaluation of the NPC \e{quality}, shown in
Section~\ref{s:r:ananpc} surfaced mixed results. The key problems
being for one, that there are quite many parameters involved; and
secondly that the analysis proved very susceptible to changes of most
of these parameters.

A quick glance at the histograms in Section~\ref{s:r:xyzhist} shows,
that the cluster considered to be the \e{best} does not look better in
fact, than most of the other clusters. We may well consider this
approach failed.

Nevertheless we might have gained some valuable insight, into why this
approach doesn't work. Reasons for this may be any and all of the
following, for some of which we may suggest possible improvements.

\begin{description}
\item [numbers] The clusters consist of very few localisations each,
  statistical analysis of so few elements have to be considered
  shaky. More constituents within each cluster would probably make
  this analysis more reliable.
\item [quality] The definitions of the two quality entities
  \e{ringness} and \e{twofold}, might not be derived well using RMS. A
  more sophisticated approach to quantify the clusters deviations to
  our known NPC geometry might work better, such as fitting the
  histogram in z direction to a Gaussian.
\item [weighting] The equal weighting of \e{ringness} and \e{twofold}
  quantities are canceling each other; Some clusters might look very
  \e{ringlike}, but are not at all stacked on top of each other, and
  vica versa. Unequal weighting based on empirical fine tuning might
  lesser this problem, but will most likely not solve it.
\end{description}

\subsection{Secondary Filter}

Some of the results of the NPC analysis might still prove themselves
useful as a secondary filters. In reducing the clusters until only a
few remain, effectively also finds the \e{best}.

\begin{description}
\item [high variance] One might want to exclude clusters with an
  overly high variance, as these might be in fact two NPCs too close
  to each other to be accounted separately by the clustering
  algorithm.
\item [low variance] Quite similarly we might exclude those clusters
  showing extremely low variance, under suspicion of being well
  concentrated---yet noise, not representing a NPC at all.
\item [spread] Likewise we may exclude clusters spreading far in z,
  due to our knowledge of the NPC heigth, as well as in x,z due to the
  NPCs well defined radius.
\end{description}

In the end, possessing a list of the clusters position allows for a
much easier way to plot some of them manually, than to zoom in on a
plot of thousands of localisations repeatedly.


% .        ___                    ___         ___             ___         ___   ___                          ___  
% .   .'|=|_.'   .'|=|`.     .'| |   |   .'|=|_.'   .'|      |   | |`.   |   |=|_.'   .'|   .'|=|`.     .'| |   | 
% . .'  |      .'  | |  `. .'  |\|   | .'  |      .'  |      |   | |  `. `.  |      .'  | .'  | |  `. .'  |\|   | 
% . |   |      |   | |   | |   | |   | |   |      |   |      |   | |   |   `.|=|`.  |   | |   | |   | |   | |   | 
% . `.  |  ___ `.  | |  .' |   | |  .' `.  |  ___ |   |  ___ `.  | |   |  ___  |  `.|   | `.  | |  .' |   | |  .' 
% .   `.|=|_.'   `.|=|.'   |___| |.'     `.|=|_.' |___|=|_.'   `.|=|___|  `._|=|___||___|   `.|=|.'   |___| |.'   
% .       
\chapter{Conclusion}

\section{Phase Retrieval}

The Zernike modes for both red and blue channel are estimated via
phase retrieval of in-focus measurements of beads at various
depths. This yields a full PSF model to be used for de-focus 3d SMLM.


\section{Correction Collar}

The best setting of the Correction Collar for the Olympus \SI{1.5}{\NA}
objective is shown to be 0.13. Here we find the preferable compromise
between x,y precision and z precision, in the regime between about 0
and \SI{250}{\micro\meter}.


\section{dSTORTM Buffer}


\appendix


\section{SMLM Analysis: NPC}

\onecolumn

\usemintedstyle{
  manni,
  linenos = true,
  frame = single,
}

\subsection{Import}

\begin{minted}{python}
  #@markdown ##import core
  import pandas as pd
  import matplotlib.pyplot as plt
  import numpy as np
  import matplotlib as mpl
  from mpl_toolkits.mplot3d import Axes3D
  import scipy.io
  from sklearn.cluster import DBSCAN
  from sklearn import metrics
  from sklearn.datasets import make_blobs
  from sklearn.preprocessing import StandardScaler

  #@markdown ##import jupyter
  #%matplotlib ipympl
  #%matplotlib widget
  #%matplotlib interactive
  % matplotlib inline
  import trackpy
  #import sdt
  #from sdt import io, chromatic, multicolor, brightness
  
  ## local
  wd = 'data/210422_npc_red_defocus/'
  data = pd.read_csv( wd + 'cell1_tr1000_def500.csv',
  header = None,
  names=["x", "y", "z", "n", "bg","fit","id","frame"] )
\end{minted}

\subsection{Drift Correction}

\begin{minted}{python}
  #@markdown ## import & scale drift
  #@markdown > set **magnification** via factor in drift.

  drift = pd.read_csv( wd + 'day2_cell1_driftValues.csv')

  drift['Y2']=drift['Y2']*146.6
  drift['Y3']=drift['Y3']*146.6
  drift['X2']=np.round(drift['X2'])
  drift['X3']=np.round(drift['X3'])

  #@markdown ## apply drift correction

  for i in range(len(drift)-1):
  fr=data[(data['frame']>=drift['X2'].iloc[i]) &
  (data['frame']<drift['X2'].iloc[i+1])]
  fr['y']=fr['y']-drift['Y2'].iloc[i]
  fr['x']=fr['x']-drift['Y3'].iloc[i]
  data[(data['frame']>=drift['X2'].iloc[i]) &
  (data['frame']<drift['X2'].iloc[i+1])]=fr
\end{minted}


\subsection{Photon Counts}

\begin{minted}{python}
  #@markdown ## Check: photon counts
  #@markdown > set `max_photons` accordingly (default: 10000).
  max_photons = 10000 #@param {type:"slider", min:0, max:40000, step:1000}
  
  fig = plt.figure()
  plt.hist( data['n'], bins=50, range=( 0, max_photons ) )
\end{minted}


\subsection{Filter}

\begin{minted}{python}
  #@markdown ## filter
  #@markdown > set `min_photons` and `max_photons` accordingly (default: 2000 < photons < 7000).\
  #@markdown > set `min_z` and `max_z` accordingly (default: 0 < z < 499).\
  #@markdown > set `min_fit` accordingly (default: 6e6).
  min_photons = 2000 #@param {type:"slider", min:0, max:40000, step:1000}
  max_photons = 7000 #@param {type:"slider", min:0, max:40000, step:1000}
  min_z = 0 #@param {type:"slider", min:0, max:500, step:1}
  max_z = 384 #@param {type:"slider", min:0, max:500, step:1}
  min_fit = 7192000 #@param {type:"slider", min:0, max:1e7, step:1000}
  
  fdata = data[ ( data['n'] > min_photons ) &
  ( data['n'] < max_photons ) & 
  ( data['z'] > min_z ) &
  ( data['z'] < max_z ) &
  ( data['fit'] < min_fit ) ]
\end{minted}


\subsection{Track Particles}

\begin{minted}{python}
  #@markdown ## track all in x,y
  #@markdown > set `sr` to wanted search range (default: 50).\
  #@markdown > set `mem` to wanted memory (default: 10).
  sr = 50 #@param {type:"slider", min:0, max:100, step:1}
  mem = 10 #@param {type:"slider", min:0, max:100, step:1}
  
  linkedxy = trackpy.link_df( fdata,
  pos_columns = ["x","y","z"],
  search_range = sr,
  memory = mem )
  
  particles = linkedxy.groupby( "particle" ).aggregate( np.mean )
  std_pos = linkedxy.groupby( "particle" ).aggregate( 'std' )
  particles["length"] = linkedxy.groupby( "particle" ).apply( len )
  particles["z_std"] = std_pos['z'].copy()
  particles["x_std"] = std_pos['x'].copy()
  particles["y_std"] = std_pos['y'].copy()
\end{minted}


\section{SMLM Analysis: NPC}

\subsection{Clustering}

\begin{minted}{python}
  #@markdown ## compute dbscan
  #@markdown > set `dim = 2` for clustering in x and y (default:).\
  #@markdown > set `dim = 3` for experimental clustering in 3d; be aware that x,z and y precision probably vary!\
  #@markdown > set `eps` (default: 200).\
  #@markdown > set `min_samples` (default: 10).
  dim = "2" #@param [2, 3]
  eps = 100 #@param {type:"slider", min:0, max:500, step:10}
  min_samples = 50 #@param {type:"slider", min:1, max:100, step:1}

  alocalisations = localisations.to_numpy()
  alocalisations[ :, 0:2 ]

  db = DBSCAN( eps, min_samples ).fit( alocalisations[ :, 0:int( dim ) ] )
  core_samples_mask = np.zeros_like( db.labels_, dtype=bool )
  core_samples_mask[ db.core_sample_indices_ ] = True
  labels = db.labels_
  localisations[ "cluster" ] = labels

  # count clusters (ignore noise if present)
  n_clusters_ = len( set( labels ) ) - ( 1 if -1 in labels else 0 )
  n_noise_ = list( labels ).count( -1 )

  #print('Estimated number of clusters: %d' % n_clusters_)
  #print('Estimated number of noise points: %d' % n_noise_)

  nlocalisations = localisations.loc[ localisations['cluster'] == -1 ]
  clocalisations = localisations.loc[ localisations['cluster'] != -1 ]
\end{minted}


\subsection{Cluster Analysis}

\begin{minted}{python}
  #@markdown ## analyse clusters
  #@markdown > set `npc_radius` to NPC radius /nm (default: 50).\
  #@markdown > set `npc_radius` to NPC haight /nm (default: 150).
  npc_radius = 50 #@param {type:"slider", min:0, max:500, step:1}
  npc_height = 25 #@param {type:"slider", min:0, max:500, step:1}

  clabels = set(labels)
  cnames = [ "counts", "xmean", "ymean", "zmean", "nmean", "xvar", "yvar", "zvar",
  "nvar", "label", "ringness", "twofold" ]
  clusters = pd.DataFrame( index = clabels, columns = cnames, dtype="float64" )
  clusters[ "label" ] = clabels

  for k in clabels:
  tmp = localisations.loc[ localisations['cluster'] == k ]
  clusters.loc[ k, "counts" ] = len( tmp )
  for label in [ "x", "y", "z", "n" ]:
  clusters.loc[ k, label+"mean"  ] = np.mean( tmp.loc[ :, label ] )
  clusters.loc[ k, label+"var"  ] = np.var( tmp.loc[ :, label ] )

  ## xy: radius (distance to centroid)
  rad = np.sqrt( ( tmp.loc[ :, "x" ] - clusters.loc[ k, "xmean" ] )**2 + 
  ( tmp.loc[ :, "y" ] - clusters.loc[ k, "ymean" ] )**2 )
  ## xy: radius rms deviation from NPC radius
  clusters.loc[ k, "ringness"  ] = np.sqrt( sum( ( rad - npc_radius )**2 ) )

  ## z: radius (distance to centroid)
  rad = abs( tmp.loc[ :, "z" ] - clusters.loc[ k, "zmean" ] )
  ## z: radius rms deviation from NPC radius
  clusters.loc[ k, "twofold"  ] = np.sqrt( sum( ( rad - npc_height )**2 ) )

  #@markdown ## filter clusters
  #@markdown > set `count_threshold` to min elements (counts) in cluster (default: 30)\
  #@markdown > set `diameter_threshold` to max x,y (radius) deviation of cluster from NPC diameter (default: 200)\
  #@markdown > set `twofold_threshold` to max z (radius) deviation of cluster from NPC height (default: 200)\
  #@markdown > set `xyvar_threshold` to wanted x,y variance (default: 1e4)\
  #@markdown > set `zvar_threshold` to wanted z variance (default: 1e4)
  count_threshold = 100 #@param {type:"slider", min:0, max:200, step:1}
  diameter_threshold = 500 #@param {type:"slider", min:0, max:500, step:10}
  twofold_threshold = 1000 #@param {type:"slider", min:0, max:1000, step:10}
  xyvar_threshold = 100000 #@param {type:"slider", min:0, max:1e5, step:1e3}
  zvar_threshold = 100000 #@param {type:"slider", min:0, max:1e5, step:1e3}

  fclusters = clusters[ ( clusters['counts'] < count_threshold ) &
  ( clusters['ringness'] < diameter_threshold ) &
  ( clusters['twofold'] < twofold_threshold ) &
  ( clusters['xvar'] < xyvar_threshold ) & 
  ( clusters['yvar'] < xyvar_threshold ) &
  ( clusters['zvar'] < zvar_threshold ) ]
\end{minted}


\subsection{Select Clusters}

\begin{minted}{python}
  #@markdown ## select best clusters & plot localisations
  #@markdown > set `show_clusters` to wanted number of best clusters (default: 100).\
  #@markdown > set `sort` to sort the best clusters (default: ringness + twofold).
  show_clusters = 10 #@param {type:"slider", min:0, max:1000, step:1}
  sort = 'ringness + twofold' #@param [ "ringness + twofold", "twofold", "ringness", "xyvar" , "xvar" ]

  if sort == "xvar": # sort by variance
  sclusters = fclusters.sort_values( "xvar" )
  elif sort == "xyvar": # sort by x and y variance using least squares
  sclusters = fclusters.loc[
  ( fclusters.xvar ** 2 + fclusters.yvar ** 2 ).sort_values().index ]
  elif sort == "ringness": # sort by ringness (deviation to ringness)
  sclusters = fclusters.sort_values( "ringness" )
  elif sort == "twofold": # sort by ringness (deviation to ringness)
  sclusters = fclusters.sort_values( "twofold" )
  elif sort == "ringness + twofold": # sort by ringness (deviation to ringness)
  sclusters = fclusters.loc[
  ( fclusters.twofold ** 2 + fclusters.ringness ** 2 ).sort_values().index ]

  show_clusters = min( show_clusters, len( sclusters ) )
  selected_clusters = sclusters["label"].iloc[ 0:show_clusters ]

  fig = plt.figure()
  ax = fig.add_subplot( projection = '3d' )
  for clus in selected_clusters:
  flocalisations = localisations[ ( localisations['cluster'] == clus ) ]
  ff = ax.scatter( flocalisations['x'],
  flocalisations['y'],
  flocalisations['z'],
  s=1 ,c = flocalisations['n'] )
\end{minted}


\subsection{X,Y,Z Histograms}

\begin{minted}{python}
  #@markdown ## Check: z distribution
  #@markdown > set `plot_cluster` to wanted cluster (default: 0).
  plot_cluster = 3  #@param {type:"slider", min:0, max:100, step:1}
  plot_cluster = min( plot_cluster, len( sclusters ) -1 )

  tmp = localisations.loc[ localisations['cluster'] == 
  sclusters.loc[ sclusters.index[ plot_cluster ],
  "label" ] ]

  z = tmp.z - np.mean( tmp.z )

  fig, axes = plt.subplots(2, 1, figsize=(4, 7) ) # figsize=(4, 12)

  axes[0].hist( tmp.z - np.mean( tmp.z ) )
  axes[0].set_xlabel('z / nm')
  axes[0].set_ylabel('counts')
  #axes[0].set_title( 'z' )

  axes[1].hist( tmp.x - np.mean( tmp.x ) )
  axes[1].hist( tmp.y - np.mean( tmp.y ) )
\end{minted}



% .        _                _   
% .   .'|=| `.   .'|   .'|=| `. 
% . .'  | | .' .'  | .'  | | .' 
% . |   |=|'.  |   | |   |=|'.  
% . |   | |  | |   | |   | |  | 
% . |___|=|_.' |___| |___|=|_.' 
% . 

% \clearpage \bibliography{bibliography}

% \bibliographystyle{apalike} % 'alpha' for 3 letters + year


% .                   ___   ___  ___  ___   ___  ___   ___ 
% .   .'|        .'| |   |=|_.' `._|=|   |=|_.' |   |=|_.' 
% . .'  |      .'  | `.  |           |   |      `.  |      
% . |   |      |   |   `.|=|`.       |   |        `.|=|`.  
% . |   |  ___ |   |  ___  |  `.     `.  |       ___  |  `.
% . |___|=|_.' |___|  `._|=|___|       `.|       `._|=|___|
% .

\clearpage \listoffigures


% .        ___                          ___   ___  ___   ___                    __   ___   ___  
% .   .'|=|_.'    .'|        .'|=|`.   |   |=|_.' |   |=|_.'   .'|=|`.     .'|=|  | |   | |   | 
% . .'  |___    .'  |      .'  | |  `. `.  |      `.  |      .'  | |  `. .'  | |  | `.  |_|  .' 
% . |   |`._|=. |   |      |   | |   |   `.|=|`.    `.|=|`.  |   |=|   | |   |=|.'    `.   .'   
% . `.  |  __|| |   |  ___ `.  | |  .'  ___  |  `. ___  |  `.|   | |   | |   |  |`.    |   |    
% .   `.|=|_.'' |___|=|_.'   `.|=|.'    `._|=|___| `._|=|___||___| |___| |___|  |_|    |___|    
% . 

% \glsaddallunused % add all unused terms to the glossary without including a phantom page number
% \clearpage \printacronyms


% .              ___                     ___  ___   ___  
% .   .'|   .'| |   |   .'|=|`.     .'|=|_.' |   | |   | 
% . .'  | .'  |\|   | .'  | |  `. .'  |  ___ `.  | |  .' 
% . |   | |   | |   | |   | |   | |   |=|_.'  .` |=| `.  
% . |   | |   | |  .' |   | |  .' |   |  ___ |   | |   | 
% . |___| |___| |.'   |___|=|.'   |___|=|_.' |___| |___| 
% . 

% \clearpage \printindex


% .  ___  ___   ___                    ___           ___        ___              
% . `._|=|   |=|_.'   .'| |`.     .'|=|_.'      .'|=|_.'   .'| |   |   .'|=|`.   
% .      |   |      .'  | |  `. .'  |  ___    .'  |  ___ .'  |\|   | .'  | |  `. 
% .      |   |      |   |=|   | |   |=|_.'    |   |=|_.' |   | |   | |   | |   | 
% .      `.  |      |   | |   | |   |  ___    |   |  ___ |   | |  .' |   | |  .' 
% .        `.|      |___| |___| |___|=|_.'    |___|=|_.' |___| |.'   |___|=|.'   
% . 

\end{document}