% arara: lualatex: { shell: true, synctex: true, interaction: nonstopmode }
% arara: bibtex
% arara: makeglossaries
%% arara: makeuaindex
% arara: lualatex: { shell: true, synctex: true, interaction: nonstopmode }
% arara: lualatex: { shell: true, synctex: true, interaction: nonstopmode }
\documentclass[11pt, a4paper, oneside, twocolumn]{report}

\asdfasdf

% .
% .            |   |  _)                  
% .   __|  _ \ __| __| | __ \   _` |  __| 
% . \__ \  __/ |   |   | |   | (   |\__ \ 
% . ____/\___|\__|\__|_|_|  _|\__, |____/ 
% .                           |___/       
% .
%% packages --------------------------------------------------------------------
\usepackage{hyphenations} % thats my own hyphenation list
% \usepackage[english]{babel}
\usepackage[font={it}]{caption}
\usepackage[noend]{algpseudocode}
\usepackage[chapter]{mytodo} % thats my own todo package based on easy-todo
\usepackage{
  amsmath,
  amssymb,
  floatpag,
  graphicx,
  hhline,
  hyphenat,
  ifdraft,
  listings,
  makeidx,
  minted,
  pdfpages,
  pgfplots,
  siunitx,
  soul,
  subcaption,
  tabularx,
  tikzinput,
  unicode-math,
  xcolor}
\usepackage[nottoc]{tocbibind} % hide toc itself from toc
\usepackage[hidelinks]{hyperref} % always load last!
\usepackage[acronym,nomain,toc]{glossaries} % always load after hyperref!
%% settings --------------------------------------------------------------------
\pgfplotsset{%
  width  = \textwidth,
  height = \textwidth,
  compat = 1.17,
  colormap name = viridis,
  cycle list name = exotic,
  table/search path={data},
} % TikZ doesnt know the twocolumn thing
\usetikzlibrary{external}
\usetikzlibrary{calc}
\tikzexternalize[optimize=false,prefix=tikz/] % externalize tikz, much faster, many conflicts!
\setcounter{secnumdepth}{2} % set level of depth for numbering
\graphicspath{{figures/}}
\renewcommand{\arraystretch}{1.2} % streches row heigth in arrays (and tables)
\DeclareSIUnit\molar{\mole\per\cubic\deci\metre}
\DeclareSIUnit\Molar{\textsc{m}}
\DeclareSIUnit\NA{\textsc{na}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
%% makros ----------------------------------------------------------------------
\renewcommand{\b}{\textbf}
\renewcommand{\u}{\underline}
\renewcommand{\tt}{\texttt}
\renewcommand{\t}{\todo}
\newcommand{\e}{\emph}
\newcommand{\n}{\textnormal}
\newcommand{\m}{\mathrm}
\newcommand{\x}[1]{#1\index{#1}}
% .
% .        |                                  
% .   _` | |  _ \   __|  __|  _` |  __| |   | 
% .  (   | | (   |\__ \\__ \ (   | |    |   | 
% . \__, |_|\___/ ____/____/\__,_|_|   \__, | 
% . |___/                              ____/  
% .
\makeindex
\makeglossaries % definitions in a separate file and load it in the preamble after \makeglossaries
% \loadglsentries{glossary} % also disable option "nomain"
\loadglsentries{acronyms}
% 
% .  |  _) |   |      
% .  __| | __| |  _ \ 
% .  |   | |   |  __/ 
% . \__|_|\__|_|\___|
% 
\begin{document}
\begin{titlepage}
  \onecolumn
  \centering
  \large
  a\\
  \vspace{.5cm}
  {\Large \textsc{Projektarbeit / Student Project}}\\
  \vspace{1cm}
  {\Huge \textsc{Three Dimensional Dual Colour Single Molecule Localisation Fluorescence Microscopy}}\\
  \vspace{1cm}
  concluded at the\\
  \vspace{.5cm}
  {\Large \textsc{Technische Universit\"at (Tu) Wien}}\\
  \vspace{.5cm}
  advised by\\
  \vspace{.5cm}
  {\Large \textsc{Lukas Velas}}\\
  \vspace{.5cm}
  of\\
  \vspace{.5cm}
  {\Large \textsc{Moritz Siegel}}\\
  \vfill
  \includegraphics[scale=.5]{npc/npc256.png}\\
  \vfill
  Vienna\\
  \today\\
  \vspace{.5cm}
  \small{\href{mailto:moritz.siegel@tuwien.ac.at}{moritz.siegel@tuwien.ac.at}}\\
  \small{\url{https://github.com/imrahilias/biophysics}}\\
\end{titlepage}
% .
% .        |          |                  |   
% .   _` | __ \   __| __|  __| _` |  __| __| 
% .  (   | |   |\__ \ |   |   (   | (    |   
% . \__,_|_.__/ ____/\__|_|  \__,_|\___|\__| 
% .
% \clearpage \onecolumn \chapter*{Abstract}
% asdf
% 
% \vfill
% 
% \section*{Keywords}
% asdf\\
% .
% .  |              
% .  __|  _ \   __| 
% .  |   (   | (    
% . \__|\___/ \___|
% .       
\clearpage \tableofcontents
\clearpage \listoftodos % conflict: comment out \listoftodos when externalizing tikz, or use "\tikzexternalize[optimize=false]"
% .
% . _)       |             
% .  | __ \  __|  __| _ \  
% .  | |   | |   |   (   | 
% . _|_|  _|\__|_|  \___/  
% .                      
\clearpage\chapter{Introduction}

For centuries humans use optical microscopes from magnifying glasses
to telescopes to study things smaller than our human eye is able to
resolve. Because of electro-magnetic phenomena like interference,
using visible light limits the obtainable resolution to
about \SI{200}{nm}--depending witch of the two definitions of
\x{resolution} \textsc{Abbe} or \textsc{Rayleigh} is used. Many recent
microscope techniques like X-ray microscopy, electron microscopy or
atomic force microscopy enable resolutions far beyond optical
microscopy. Most of these techniques work fine for solids, but are
lethal to living organisms, hence optical microscopy is still
ubiquitous in life-science.\\

The nobel-price \cite{np14} awarded technique of \gls{smlm} has become
one of many microscope techniques to circumvent \textsc{Abbeâ€™s}
\x{diffraction limit}, enabling the study of living structures smaller
than half the wavelength of light; thus reaching \x{super resolution}
\x{fluorescence microscopy}.\\

The ultimate goal of this thesis is to facilitate dual colour three
dimensional single molecule microscopy, by alternating excitation with
different lasers while measuring on the same single channel.

\section{Fluorescence}\label{i:fl}

The phenomenon of fluorescence exceeds classical optics, thus can only
be fully described using quantum mechanics. Here a simplified model is
used to explain the concepts necessary for \gls{smlm}. Electromagnetic
radiation in the form of a photon $h\nu_{ex}$ can be absorbed by a
molecule, lifting the molecule from its \x{ground state} $S_0$ to a
higher state $S_1$--albeit losing some energy $\Delta E$ in the form
of heat dissipation of excited \x{vibrational states}:

\begin{equation}
  S_0 + h\nu_{ex} \rightarrow  S_1 + \Delta E
\end{equation}

where $\nu_{ex}$ denotes the \e{excitation} frequency of the
incoming photon, and $h$ the Planck constant.

Some molecules called \x{fluorophores} tend to show the opposite
reaction immediately after irradiation: The emittance of a
fluorescence photon $h\nu_{em}$:

\begin{equation}
  S_1 \rightarrow  S_0 + h\nu_{em} + \Delta E
\end{equation}

Due to dissipation, the frequency of the emitted photons is lower than
those of the initially absorbed photons:

\begin{equation}
  \nu_{em} \le \nu_{ex}
\end{equation}

which leads to the discrimination between
\textsc{Rayleigh} and \textsc{Stokes} shift:

\[ \nu_{em}
  \begin{cases}
    = \nu_{ex} & \quad \text{\x{\textsc{Rayleigh} shift}}\\
    < \nu_{ex} & \quad \text{\x{\textsc{Stokes} shift}}
  \end{cases}
\]

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{jablonski.png}
  \caption{
    Jablonski diagram including vibrational levels for absorbance,
    non-radiative decay, and fluorescence. Obtained under CC0 license from
    .
  }
  \label{f:asdf}
\end{figure}

%\protect\cite{ja22}

Both processes happen by chance, which leads to the stochastic
variables of the \x{rate} of a process $\rho$ that we can measure in
experiments as occurrence per time, and the \x{lifetime} $\tau$ of a
given state as the time between excitation and emission.
An examplary description is given as a 

Many fluorophores have other transition paths that are somewhat
rare. Notably is the radiation-free \x{inter-system crossing} to a
\x{triplet} state $T_1$. This state may have a long lifetime of up to
hours, until it eventually falls back to ground state. Emitting a much
lower energy photon $h\nu$, albeit for a long due the stable nature of
the triplet state, this effect was once considered a separate
phenomenon termed \x{phosphorescence}.

While a fluorophore in its ground state $S_0$ can shift to its excited
state $S_1$, a fluorophore in the triplet state could not absorb the
same photon to get \e{back} to the excited state $S_1$ ( at least not
of similar energy). It stays dark until it falls back to ground state
$S_0$.

There are many known issues related to fluorophores, a proper
treatment of experimental pitfalls exceed the scope of this work. One
of the more frequent issues is called \e{\x{photobleaching}}: Some
chemical reaction like oxidation might change the molecules
characteristics so it loses the ability to fluorescence for good. Some
other reaction may re-enable the fluorescence, that is one of the
reasons for the use of oxygen-depleted \x{buffers} in \gls{smlm}.

% \begin{figure}[h]
%   \centering \includegraphics[width=0.5\textwidth]{alexa.png}
%   \caption{asdf, \cite{alexa}.}
%   \label{f:alexa}
% \end{figure}


\section{Fluorescence Microscopy}

Fluorescence microscopy refers to a group of optical microscopy
techniques using fluorescence instead of reflection or transmission of
light, foremost to study organic substances. 

Since most molecules are not showing fluorescence, one needs a way to
attach fluorophores to the specimen of question. One widespread
example specimen preparation are polystyrene \e{\x{beads}}, that are
soaked in a fluorophore solution. When analysing cell constituents,
like in our case the \e{nuclear pore complex}, one must find a way to
bind fluorophores to specific structures, like proteins with the use
of antibodies. This process is complicated, a detailed explanation
would exceed the scope of this paper.

The specimen is illuminated with laser light, exciting the respective
\x{fluorophores}; causing them to emit (much weaker) light on a
slightly longer wavelength. After separation from excitation light
using spectral filters, this image is captured by a sensitive camera
like a \gls{emccd}.

The accuracy of fluorescence microscopy heavily relies on the
\gls{snr} of the emitted light. If it is used to analyse translucent
three dimensional structures, like cells, out of focus fluorophores
become a problem.

If one would excite all those fluorophores by using a laser like a
flashlight, the emitted fluorescence light from the whole cell would
mix and ultimately not allow for a precise localisation of the surface
attached to the cover slip. Yet for the study on the scale of membrane
constituents only the surface of the cell attached to the cover slip
is of interest, not the whole cell. One way to restrict the
fluorescence to a thin layer, is to only excite a thin layer in the
first place.


\section{Total Internal Reflection}\index{total internal reflection}

To restrict the excitation to a thin layer of the specimen, usually
less than 200 nanometers, \gls{tirf} microscopy can be used. As the
name suggests \gls{tirf} makes use of the fact that radiation with an
incident angle greater than the critical angle of the border between
two media is totally reflected (based on Snellâ€™s law of
refraction). Yet due to the quantum mechanical nature of
electromagnetic radiation, a tiny part of the energy passes into the
other medium, with its intensity perpendicular to the border
decreasing exponentially with distance to it. This leads to a
\e{\x{evanescent field}} or \e{\x{evanescent wave}}, with a depth of a
few \SI{100}{nm} for visible light. \gls{tirf} microscopy uses this by
shining a laser onto the cover slip at a supercritical angle, and so
solely excites the few hundred nanometers of the cell wall attached to
the cover slip. TIRF results in a thin slice of the three dimensional
specimen, which may either be treated as flat surface by 2d
localisation, or as a thin 3d space by appropriate 3d localisation
techniques.


\section{Single Molecule Localisation}\index{single molecule localisation}

In order to prevent two neighbouring fluorophores to overlap, which
prohibits distinction and so ultimately limits the obtainable
resolution; the basic principle of \gls{dstorm} and many other
\gls{smlm} techniques is to separate the signal of neighbouring
individual emitters in \e{time}, which allows to determine their
positions with a precision only limited by its intensity:

\begin{equation}
  \Delta x = \frac{ \Delta k }{ \sqrt{n} }
\end{equation}

where $\Delta x$ is the localisation precision, $\Delta k$ is the
\gls{fwhm} of the \gls{psf} and $n$ is the intensity as number of
collected photons.

First, all fluorophores are put to their triplet state with intense
laser light of appropriate frequency depending on the fluorophore
used. In our experimental setup this means the live image gets visibly
darker the more fluorophores reside in the triplet state, until dark
enough to start the recording (usually a few seconds).

Now that most fluorophores reside in their dark state, upon laser
activation with typically \SI{405}{\nm}, only the very few residing
others switch to their \e{on} state. They repeatedly emit light by
alternating between singlet state $S_1$ and ground state $S_0$ as
described in section \ref{i:fl}. For some fractures of a second this
results in fluorophore \e{blinking}, until they fall back into their
\e{off} states. This somewhat static image is recorded, much like a
snapshot of the night sky with a shutter speed of 1/50~s.

This process has to be repeated many times, until all the fluorophores
have been \e{on} several times stochastically. In our case this yields
50000 frames, each consisting of many, but mostly not neighbouring
emitters.


\section{Two Dimensional SMLM}

For obtaining 2d localisations, it is convenient and most often
precise enough to fit a \textsc{\x{Gaussian}} to each of the diffuse
dots in the frame, in order to estimate their centre---thus, the
position of the fluorophore in sub-pixel resolution. For this thesis
we used the ImageJ plugin \e{ThunderSTORM} \cite{omk14} for this task.

\begin{figure}[h]
  \centering \includegraphics[width=0.5\textwidth]{2dsmlm.png}
  \caption{Influence of imaging parameters on the reconstructed SMLM
    image. The actual localization (left column) of the protein
    molecules (circles) yielding the obtained localization (right
    column), \cite{smlm}.}
  \label{f:2dsmlm}
\end{figure}

In Figure~\ref{f:2dsmlm}, a summary of the principle of 2d \gls{smlm}
is shown, including the common pitfalls: Due to localization errors,
the localizations are slightly displaced from the true molecule
positions (a). In addition, the structure is distorted or
misrepresented by decreased labeling efficiency (b), label
displacement (c) or over counting (d), \cite{smlm}.


\section{Three Dimensional SMLM}

To be able to accurately estimate the three dimensional location of
the fluorescent molecule, the PSF must be known quite well. Simply
put: If one knows the shape of a point source in varying degrees of
defocus, one can guess the defocus and thus the z coordinate of the
fluorescence molecule.

Fitting a full point spread function (PSF)---using prior calculated
\textsc{Zernike} Modes---to such a stack of images containing
reasonably spaced fluorescence signals even yields a list of 3d
localisations, as explained in detail in \ref{zbv20}.

% .
% .                 |   |               |      
% .  __ `__ \   _ \ __| __ \   _ \   _` |  __| 
% .  |   |   |  __/ |   | | | (   | (   |\__ \ 
% . _|  _|  _|\___|\__|_| |_|\___/ \__,_|____/ 
% .
\clearpage\chapter{Methods}


\section{Maximum Likelihood}\label{s:m:mle}

For the Analysis of \gls{dstorm} fluorescence microscopy,
\gls{mle}\index{maximum likelihood estimation} is widely accepted as a
gold standard; We closely follow the method from \cite{zkr18} here.

First we assume the amount of photons $n_k$ detected in pixel $k$ can
be described by a \textsc{Poissonian} probability
distribution\index{Poissonian probability distribution}:

\begin{equation}
  P_k(n_k | \mu_{\symbf{\theta},k}) = \n{e}^{-\mu_{\symbf{\theta},k}} \frac{\mu_{\symbf{\theta},k}^{n_k}}{n_k!}
\end{equation}

where the \x{expectation values} $\mu_{\symbf{\theta},k}$ is defined
as:

\begin{equation}
\mu_{\symbf{\theta},k} = \beta +  s *h_k( x_0, y_0, z_0 )
\end{equation}

depending on the form of the \gls{psf} model $h$ and on the
\x{parameter vector} $\symbf{\theta}$:

\begin{equation}
  \symbf{\theta} = (\beta, s, x_0, y_0, z_0)
\end{equation}

with $\beta$ and $s$ denoting the mean photon numbers for background
level respective signal; and $x_0, y_0, z_0$ denote the particle
position in 3d.

For each recorded frame, the parameter vector $\symbf{\theta}$ is
estimated by finding a minimum of the total \x{negative log-likelihood
  function} using the \x{MATLAB} tool \tt{\x{fminunc}}:


\begin{equation}
\symbf{\theta} = \argmin_{\symbf{\theta}} \sum_{k}{\mu_{\symbf{\theta},k} - n_k \ln{\mu_{\symbf{\theta},k}}}
\end{equation}


\section{PSF Model \& Zernike}\label{s:m:psf}

In first order approximation the \gls{psf} can be \x{aberration-free},
but for \gls{smlm} this is not going to be precise enough. In this
thesis we employ a \gls{psf} model\index{point spread function model}
expressed in a \textsc{Zernike}\index{Zernike modes} modes basis using
\textsc{Noll}\index{Noll coefficients} coefficients ranging from 2 to
37 (3rd order \x{spherical aberration}s) plus the 4th order spherical
mode $Z_{56}$ \cite{zkr18}:

\begin{equation}
\Phi = a_{56}Z_{56} + \sum_{i=1}^{37}{ a_iZ_i }
\end{equation}


\begin{figure}[h]
  \centering \includegraphics[width=0.5\textwidth]{zern.png}
  \caption{
    The first 21 Zernike polynomials, ordered vertically by radial
    degree and horizontally by azimuthal degree, obtained under CC-BY-SA
    license from \cite{zern}.
  }
  \label{f:zern}
\end{figure}

\section{STORM \& dSTORM}\label{s:m:storm}

We used \x{dSTORM microscopy} throughout this thesis, which is the
\e{direct} variant of STORM, utilising very bright fluorophores, with
a high rate of \x{photoswitching} and minimal
\x{photobleaching}, based on \cite{hls08}.


\subsection{Gloxy Buffer}\label{s:m:gloxy}

The principle of \gls{storm} on cells is based on an appropriate
\e{\x{storm buffer}}, which suppresses the activation of the
\e{\x{bright state}}, and limits the amount of oxygen, the main source
of photobleaching.

Single color \gls{smlm} at \SI{645}{\nm} (red) employs the
\acrshort{gloxy} buffer\index{Gloxy buffer}, so called after its
central ingredients \x{glucose} and \x{glucose oxidase}. We used
throughout this paper for all single channel measurements at
\SI{645}{\nm} unless noted otherwise.

\subsubsection{Gloxy buffer concentration}
\begin{itemize}
\item 50 \si{\milli\mol} \gls{mea} (Sigma-Aldrich).
\item 10~vol\% of a \SI{250}{\g\per\L} solution of glucose.
\item \SI{0.5}{\mg\per\ml} glucose oxidase.
\item \SI{40}{\mg\per\ml} \x{catalase} (Sigma-Aldrich).
\item with \gls{pbs}\index{phosphate-buffered saline} adjust to pH 7.6 .
\end{itemize}

\subsection{OxEA Buffer}\label{s:m:oxea}

Dual colour fluorescence microscopy poses novel challenges to find a
proper \gls{dstorm} buffer, that simultaneously works for two distinct
fluorophores AF647 and AF488---thus both excitation
wavelengths---without interfering with each other. The buffer
composition we used is based on \cite{nab16}, and called
\acrshort{oxea}\index{OxEA buffer} after its main ingredients
\x{OxyFlour} and \gls{mea}\index{mercaptoethylamine hydrochloride}:

\subsubsection{OxEA buffer concentration}
\begin{itemize}
\item 50 \si{\milli\mol} \gls{mea} (Sigma-Aldrich).
\item 3~vol\% OxyFlourTM (Oxyrase Inc., Mansfield, Ohio, U.S.A.).
\item 20~vol\% of \x{sodium DL-lactate}, 60\% syrup (L1375, Sigma-Aldrich).
\item with \gls{pbs} adjust to pH~8--8.5 with NaOH.
\end{itemize}


\section{Dual Colour Optics}

It is possible to use different excitations to simultaneously measure
different fluorescence markers, but for that the point spread function
has to known for each wavelength. So the PSFs are estimated both for
red and blue laser light, with the \x{phase retrieval} program by
\cite{zkr18}. As a sort of \e{ground truth} due to their well known
geometry, \SI{100}{\nm} \x{beads} stained with fluorescence dyes are
used. For both red (\SI{645}{\nm}) and blue (\SI{488}{\nm}) laser
light, a stack of 50~\gls{dstorm} images is taken; each at focal
depths (from \SI{-1600}{\nm} to \SI{+1600}{\nm} in \SI{200}{\nm}
steps). the 17~stacks are averaged, and fed into the phase retrieval
program as a \tt{tiff} file, to estimate the wavelength specific PSF.


\subsection{Aberration Correction Collar}

To further complicate things, the new \SI{1.5}{\NA} \x{Olympus
  objective} comes with a \x{correction collar} to compensate for
\x{aberrations}---which naturally vary slightly for both colour
channels. In order to find the best correction collar setting of the
Olympus \SI{1.5}{\NA} objective for \gls{smlm}, the point spread
functions (PSF) is computed for each of the three settings of the
correction collar $\{0.13,0.17,0.19\}$; using the program by
\cite{zkr18}, described in Section~\ref{s:m:psf}.


\subsection{Cram\'er Rao Lower Bound}\index{Cram\'er Rao lower bound}\label{s:m:crlb}

The \gls{crlb} gives the theoretical limit for the localization
precision (with any unbiased estimator). A detailed description would
exceed the scope of this paper, the interested reader is referred to a
rather recent tutorial \cite{cwo16}.

In order to find the best correction collar setting of the Olympus
\SI{1.5}{\NA} objective for \gls{smlm}, the \gls{crlb} is computed
using the MATLAB program \tt{crlb.m}, with prior estimated \gls{psf}
via phase retrieval \cite{zkr18}.\\

The \gls{crlb}s for parameter uncertainties are given by the
corresponding diagonal elements in the \x{inverse \textsc{Fisher}
  information matrix}\index{inverse Fisher information matrix}
$\b{F}$, which is calculated as follows \cite{cwo16}:

\begin{equation} \b{F}_{m,n} = \sum_{k}
  \frac{1}{\mu_{\symbf{\theta},k}}
  \frac{\Delta \mu_{\symbf{\theta},k}}{\Delta \symbf{\theta}_m}
  \frac{\Delta \mu_{\symbf{\theta},k}}{\Delta \symbf{\theta}_n}
\end{equation}

All \gls{crlb}s are computed at a defocus position of -500~nm, in
steps of 5~nm from 0 to 500 nm. For all Estimations we assume
identical, arbitrary yet consistent signal strength (2500) respective
background (100).\\


\section{Dual Colour Projection}

Since we measure excitation with different lasers on the same channel,
we propose alternating the sets to ensure the comparability of the two
sets of images; so that they are affected by \x{drift} over time,
\x{bleaching}, etc. in the same way.

The generated image stacks are then split and fed separately through
the \gls{smlm} algorithm, since the PSF model depends on the emitted
wavelength---and thus on the excitation. The two obtained data sets
with localisations for both channels are then analysed together.

Since the methods used to obtain 3d \gls{smlm} data are wavelength
dependent, the two channels will most likely be \e{off}, yet we
ultimately want to overlay them. We hereby propose a \x{calibration}
step, based on evaluating evenly dyed beads in both channels,
analysing the localisations, and finally figuring out their offset.


\subsection{Rigid Transform}\label{s:m:rig}

In first order approximation, this offset may be thought as linear, so
the two sets are related via a \e{\x{rigid transform}}; thus only by
rotation and translation. Such a transformation can be solved easily
via linear algebra; the solution used here is one of the many known
ways, using \x{least squares} and \gls{svd}\index{singular value
decomposition} based on \cite{ahb87}.

In this short overview, the lines refer to the the function \tt{rig()}
shown in Section~\ref{s:c:rig}, where the full code is
listed. Basically, one first calculates the \x{centroid}s of the two
sets of points \tt{p},\tt{q}, and shifts both sets to their respective
centres, thus eliminating translation (block 1 at Lines~24--28). As a
second step the \e{best} (least squares) transform that \e{rotates}
the set p to the set q is found via \gls{svd} (block 2 at
Lines~30--51). As a last step the translation between set p and q is
computed using the known rotation (block 3 at line 53).


\subsection{Affine Transform}\label{s:m:affine}

The next more complex approach includes
other---nonlinear---transformations like \e{\x{shearing}} or
\e{\x{scaling}}, called an \e{\x{affine transform}}. Our approach is
based on \cite{qgy10}, and can be viewed as a more complex variant of
the rigid transform shown in Section~\ref{s:m:rig}, still using least
squares and \acrfull{svd} to find the optimal affine transform in
three dimensional \x{euclidean space}, based on \cite{ahb87}.

Between centering and \gls{svd}, which both follow the rigid
transform, a \e{\x{orthogonal reduction}} is performed (block 2 at
Lines~37--60). Here the \x{covariance matrices} of both sets \tt{p}
and \tt{q} are computed, to form their inverse via a \textsc{Choleski}
decomposition\index{Choleski decomposition} (Lines~44--49). The
already centred sets \tt{p} and \tt{q} are subsequently orthogonalised
(Lines~51--56); so that \tt{p} and \tt{q} are now solely related by a
rotational matrix.


\subsection{Simulation}\label{s:m:sim}

As a proof of concept,we performed both a rigid and an affine recovery
on simulated data. The code for this simulations is listed in
Section~\ref{s:c:sim}, as well as in the \x{Octave} program
\tt{simulate.m} at my Git repository at \cite{sie21}. First, each
simulation creates a cylinder-shaped pseudo-random point cloud \tt{p},
and deducts some projection to get a second set \tt{q}, related to
\tt{p} by either a rigid or an affine transformation.


\subsection{Projected 2d NPC}\label{s:m:2dsmlm}

As a second proof of work, we tested both rigid and affine recovery on
several real dual colour \gls{smlm} data sets of labeled \gls{npc}s of
two-colour in-focus measurements of different cells, successively
recorded within the same sample. The fluorescence images are analysed
with \e{\x{ThunderSTORM}} \cite{omk14}, a \gls{dstorm} plugin for
\e{\x{ImageJ}}, to obtain 2d localisations based on \textsc{Gaussian}
fits\index{gaussian fit}.

Since these data sets are two dimensional, we added low-magnitude
noise ($\mathcal{O}(10^{-3})$) as a virtual z component, so both sets
are projected almost onto the z plane for analysis. This is necessary,
because the singular-value-decomposition faults on 2d data.

The resulting data sets are then analysed either a rigid or an affine
transformation.

This process is centrally governed by the Octave program
\tt{cockpit.m}, which internally uses the Octave function \tt{ampel.m}
to sort the imported data file into the two alternating colour
channels. The code is listed in Section~\ref{s:c:cockpit}, and
Section~\ref{s:c:ampel}, as well as in my Git repository at
\cite{sie21}.


\subsubsection{Cockpit}
  
To begin with, the Octave program\tt{cockpit.m} acts as a framework
for the entire analysis; successively loading the content of all lokal
2d location files (unless specifically excluded using the exclude
variable). All parameters for further analysis are confined to the
settings block at the beginning, e.g. load-order corrections due to
frames being skipped, etc.


\subsubsection{Sort}

The function \tt{ampel.m} sorts (modulo) the positions in three
categories---red, blue, empty---based on the frame, in which the
respective positions have been found by prior localisation. The
illumination order (e.g. red-blue-empty) has to stay constant, but the
offset (which one of the three staging the starting frame) can, and
unfortunately currently has to be adjusted for each file manually by
specifying mod values.


\subsubsection{Cluster}

The three separate channels red/blue/empty are then clustered by
\tt{dbscan.m}, based on two parameters: euclidean distance between two
neighbours (\tt{eps}), and least number of points required to be
considered a cluster at all (\tt{minpts}). Based on these parameters,
some ensemble of dots are considered a cluster while others are not,
which is the whole point of these routines. Naturally, the number of
clusters vary with different data sets. Unfortunately though, a rigid
projection demands sets of the same size. Brief parameter tuning
reveals: Whatever parameters, some regions most likely will have to be
excluded.

% .                           
% .                      | |        
% .   __| _ \  __| |   | | __|  __| 
% .  |    __/\__ \ |   | | |  \__ \ 
% . _|  \___|____/\__,_|_|\__|____/
% .
\clearpage\chapter{Results}


\section{Dual Colour Buffer}

\subsubsection{Beads}

The beads (polystyrene spheres) we use for calibration of the phase
retrieval algorithm are soaked in \e{\x{Alexa Fluors}} \x{AF647}
respective \x{AF488} and imaged in pure water.

Living cells like our prepared \gls{npc} samples are labeled with both
\e{\x{Alexa Fluors}} \x{AF647} and \x{AF488} in \gls{gloxy} buffer,
described in detail in Section~\ref{s:m:gloxy}.

Gloxy is designed for Alexa Fluor AF647 and works with it as
expected. The buffer failed for \x{AF488} excitation with appropriate
light: The recorded intensity quickly degraded due to bleaching to
about an order of magnitude lower than for AF647.

In order to enable similarly precise dual colour three dimensional
\gls{smlm}, by using alternating excitation with red and blue laser
light the buffer constituents were found to play a central role.\\


\subsubsection{OxEA buffer protocol}

Finally the \gls{npc} samples have been evaluated using \gls{oxea}
buffer, described in detail in Section~\ref{s:m:oxea}.  OxEA was found
to work well with either red or blue excitation.

For about 1~\si{\milli\liter} of OxEA buffer we used the amounts shown
in Table~\ref{t:oxea}, to obtain above listed concentrations.\\

\begin{table}[!htb]
  \caption{Ingredients used for preparation of OxEA buffer for dual
    colour \gls{dstorm}.} \label{t:oxea}
  \begin{tabularx}{.5\textwidth}{l X l r}
    \hhline{====}
    Order & Ingredient & Store & Vol / \si{\micro\liter} \\
    \hline
    1 & Ultra pure H$_2$O & & 600 \\
    2 & \SI{10}{\Molar} NaOH & & 20 \\
    3 & 10$\times$ \gls{pbs} & & 100 \\
    4 & 60\% DL-lactate & fridge & 200 \\
    5 & \SI{1}{\Molar} \gls{mea} & freezer & 50 \\
    6 & OxyFluor & freezer & 30 \\
    \hhline{====}
  \end{tabularx}
\end{table}

The \gls{oxea} buffer did work, but offered notably less
\x{fluorophore blinking}, as well as was much lower \gls{snr} For the
red channel compared to using \gls{gloxy} buffer; with the blue
channel being worse still.

Nevertheless OxEA clearly beat Gloxy in being able to buffer both
AF647 and AF488 simultaneously, thus was used in all further
measurements.


\subsubsection{pH}

The pH of the \gls{oxea} buffer is checked using both broad range pH
testing strips, and a digital pH meter, to be between pH~7 and pH~8.


\section{Dual Colour Optics}


\subsection{Zernike Modes}\label{s:r:zern}

The calculated \textsc{Zernike} modes of the PSF are shown for each of
the three correction collar settings $\{0.13,0.17,0.19\}$, each for
blue channel respective red channel in Figure~\ref{f:zernblue}
respective Figure~\ref{f:zernred}.

For convenience the same results are additionally shown grouped by the
the three correction collar settings $\{0.13,0.17,0.19\}$, now for
both red and blue channel in Figure~\ref{f:zern013},
Figure~\ref{f:zern017} and Figure~\ref{f:zern019}.\\

The aim is now to find a correction collar setting where the
\textsc{Zernike} modes are both low and similar for red and blue
excitation.

As an overview the various settings lead to distinguishable
\textsc{Zernike} modes, yet in a similar order of magnitude (from 0 to
about 0.1~au), as can be seen in all the mentioned figures.

As an example: In Figure~\ref{f:zern017} showing setting of $0.17$,
one can see that there is a huge difference in \textsc{Zernike} mode
number 22; red light at 0.01, where blue light gives 0.06.

We can also clearly see that for the setting of $0.13$ the aberrations
for red mostly exceed those of blue light, indicating that this might
not be a good choice \textsc{Zernike} mode wise.

On the other hand we can see that while equal for red and blue the
\textsc{Zernike} modes for setting 0.19 features high lower orders,
which even if evenly for both colors is not desirable.

A closer inspection suggests that at setting 0.19 the magnitude of the
calculated \textsc{Zernike} modes is quite similar to the one with
setting 0.17, yet slightly higher in all respects; which supports
ruling out the correction color setting 0.19.

% \begin{figure*}[!t]
%   \begin{tikzpicture}
%     \begin{axis}[
%       %       enlargelimits=false,
%       smooth,
%       grid=both,
%       grid style=dashed,
%       xlabel={Zernike mode number},
%       %       xticklabels={,,},
%       ylabel={Aberration / au},
%       %       grid=major,
%       legend entries={0.13 X,0.13 X,0.13 X},
%       %       legend pos = north west,
%       ybar = 1pt,% configures `bar shift'
%       bar width = 1pt,
%       %       nodes near coords,
%       %       point meta = y*1e2, % the displayed number
%       xmin = 0,
%       xmax = 57,
%       ymin = -0.1,
%       ymax = 0.1,
%       ]
%       \addplot+ [ ybar, color=teal ]
%       table [ x=modes, y=0.13blue, col sep=comma ] {crlb/Zernikes.csv};
%       \addplot+ [ ybar, color=orange ]
%       table [ x=modes, y=0.17blue, col sep=comma ] {crlb/Zernikes.csv};
%       \addplot+ [ ybar, color=purple ]
%       table [ x=modes, y=0.19blue, col sep=comma ] {crlb/Zernikes.csv};
%     \end{axis}
%   \end{tikzpicture}
%   \caption{ asdf }
%   \label{f:axes}
% \end{figure*}


\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={Zernike mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.13 blue, 0.17 blue, 0.19 blue},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=teal ]
      table [ y=modes, x=0.13blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=orange ]
      table [ y=modes, x=0.17blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.19blue, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Blue channel \textsc{Zernike} modes $\{1\dots37,56\}$ versus
    aberrations of PSF model via phase retrieval, for all three
    correction collar settings (0.13, 0.17, 0.19).}
  \label{f:zernblue}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={\textsc{Zernike} mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.13 red, 0.17 red, 0.19 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=teal ]
      table [ y=modes, x=0.13red, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=orange ]
      table [ y=modes, x=0.17red, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.19red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red channel \textsc{Zernike} modes $\{1\dots37,56\}$ versus
    aberrations of PSF model via phase retrieval, for all three
    correction collar settings (0.13, 0.17, 0.19).}
  \label{f:zernred}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={\textsc{Zernike} mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.13 blue, 0.13 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=cyan ]
      table [ y=modes, x=0.13blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.13red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red and blue channel \textsc{Zernike} modes $\{1\dots37,56\}$
    versus aberrations of PSF model via phase retrieval, for
    correction collar setting of 0.13.}
  \label{f:zern013}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={\textsc{Zernike} mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.17 blue, 0.17 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=cyan ]
      table [ y=modes, x=0.17blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.17red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red and blue channel \textsc{Zernike} modes $\{1\dots37,56\}$
    versus aberrations of PSF model via phase retrieval, for
    correction collar setting of 0.17.}
  \label{f:zern017}
\end{figure*}

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      height = 1.3\textwidth,
      width = \textwidth,
      % enlargelimits=false,
      smooth,
      grid=both,
      grid style=dashed,
      ylabel={\textsc{Zernike} mode number},
      % xticklabels={,,},
      xlabel={Aberration / au},
      % grid=major,
      legend entries={0.19 blue, 0.19 red},
      % legend pos = north west,
      xbar = 1pt,% configures `bar shift'
      bar width = 1pt,
      % nodes near coords,
      % point meta = y*1e2, % the displayed number
      ymin = 0,
      ymax = 57,
      xmin = -0.1,
      xmax = 0.1,
      ]
      \addplot+ [ xbar, color=cyan ]
      table [ y=modes, x=0.19blue, col sep=comma ] {crlb/Zernikes.csv};
      \addplot+ [ xbar, color=purple ]
      table [ y=modes, x=0.19red, col sep=comma ] {crlb/Zernikes.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{ Red and blue channel \textsc{Zernike} modes $\{1\dots37,56\}$
    versus aberrations of PSF model via phase retrieval, for
    correction collar setting of 0.19.}
  \label{f:zern019}
\end{figure*}


\clearpage\subsection{Cram\'er Rao Lower Bound}\label{s:r:crlb}

The Estimated \acrfull{crlb} are calculated for different correction
collar settings as shown in section \ref{s:m:crlb} using the
\textsc{Zernike} modes described in section \ref{s:r:zern}.\\

All results are shown together in Figure~\ref{f:all}; the different
correction collar settings (varying linestyles for 0.13, 0.17, 0.19)
of the Olympus \SI{1.5}{\NA} objective; for $X$, $Y$ and $Z$ axis
(top, middle, and bottom); for both red and blue channel (colours).\\

Additionally plots grouped by $X, Y$ and $Z$ axis are shown in
Figure~\ref{f:axesr} for red light and Figure~\ref{f:axesb} for blue
light. Finally plots grouped by different correction collar settings
are shown in Figure~\ref{f:collarr} respective
Figure~\ref{f:collarb}.\\

The \gls{crlb} presents an estimation of the obtainable resolution
both lateral ($X$,$Y$) as well as depth ($Z$).

Obviously the various correction collar settings lead to different
obtainable resolution. For SMLM we are interested in defocusing some
\SI{200}{nm}, so we want the lowest possible $X,Y$ and $Z$ \gls{crlb}
values, ideally for both red and blue.\\

From \ref{f:all} it can be seen that the \gls{crlb} values are roughly
the same for red and blue light. So we only need to select the
correction collar with the best overall resolution, thus the lowest
\gls{crlb} values. An inspection of Figure~\ref{f:collarr} hints to
the exclusion of the 0.19 setting, as the depth ($Z$) \gls{crlb} is
quite high in the range between 0 and \SI{250}{nm}.

On the one hand both the $X$ and $Y$ \gls{crlb} values for correction
collar setting 0.19 and 0.17 are lower than 0.13 in the range between
0 and \SI{250}{nm}. On the other hand the depth resolution $Z$
\gls{crlb} values for 0.19 and 0.17 are much higher than for 0.13.

Considering both the lateral ($X$,$Y$) as well as depth ($Z$)
resolution, we might consider 0.13 or 0.17 both offer a good
compromise. 0.13 features better depth while worse lateral resolution,
and 0.17 vica versa.

\begin{figure*}[!t]
  \begin{tikzpicture}
    \begin{axis}[
      % xmin=0,
      % xmax=10,
      ymin=0,
      ymax=60,
      % cycle list name = exotic,
      % cycle list name=linestyles*,
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xlabel={Z Position / \n{nm}},
      ylabel={X,Y,Z \textsc{Cram\'er Rao} lower bound / \n{nm}},
      grid=major,
      legend entries={X 0.13 blue, X 0.17 blue, X 0.19 blue, X 0.13 red, X 0.17 red, X 0.19 red,
        Y 0.13 blue, Y 0.17 blue, Y 0.19 blue, Y 0.13 red, Y 0.17 red, Y 0.19 red,
        Z 0.13 blue, Z 0.17 blue, Z 0.19 blue, Z 0.13 red, Z 0.17 red, Z 0.19 red },
      legend pos = north west,
      ]
      \addplot[ color=cyan ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_013_blue2.csv };
      \addplot[color=cyan, dotted, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_017_blue2.csv};
      \addplot[color=cyan, densely dotted, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_019_blue2.csv};
      \addplot[color=purple, loosely dotted, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_013_red2.csv};
      \addplot[color=purple, dashed, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_017_red2.csv};
      \addplot[color=purple, densely dashed, very thick ]
      table [ x=n, y=x, col sep=comma ] {crlb/crall_019_red2.csv};
      \addplot[color=cyan, loosely dashed, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_013_blue2.csv };
      \addplot[color=cyan, dashdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_017_blue2.csv};
      \addplot[color=cyan,densely dashdotted, very thick  ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_019_blue2.csv};
      \addplot[color=purple, loosely dashdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_013_red2.csv};
      \addplot[color=purple, dashdotdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_017_red2.csv};
      \addplot[color=purple, densely dashdotdotted, very thick ]
      table [ x=n, y=y, col sep=comma ] {crlb/crall_019_red2.csv};
      \addplot[color=cyan, loosely dashdotdotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_013_blue2.csv };
      \addplot[color=cyan ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_017_blue2.csv};
      \addplot[color=cyan, dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_019_blue2.csv};
      \addplot[color=purple, densely dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_013_red2.csv};
      \addplot[color=purple, loosely dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_017_red2.csv};
      \addplot[color=purple, loosely dotted, very thick ]
      table [ x=n, y=z, col sep=comma ] {crlb/crall_019_red2.csv};
    \end{axis}
  \end{tikzpicture}
  \caption{Estimated \textsc{Cram\'er Rao} lower bound for different correction
    Collar settings (varying linestyles for 0.13, 0.17, 0.19) of the
    Olympus \SI{1.5}{\NA} objective; for X, Y and Z axis (top, middle,
    and bottom); for both red and blue channel (colours).}
  \label{f:all}
\end{figure*}
~ % dirty hack

% 
\begin{figure}[!t]
  \begin{subfigure}[t!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 X,0.17 X,0.19 X},
        % legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 Y,0.17 Y,0.19 Y},
        % legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        xlabel={Z Position / \n{nm}},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 Z,0.17 Z,0.19 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \caption{ Estimated \textsc{Cram\'er Rao} lower bound for blue light
    for different correction Collar settings (teal: 0.13, orange: 0.17,
    purple: 0.19) of the Olympus \SI{1.5}{\NA} objective; grouped by X, Y
    and Z axis (top, middle, and bottom).}
  \label{f:axesb}
\end{figure}
% 
\begin{figure}[!t]
  \begin{subfigure}[t!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,        
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 X,0.13 Y,0.13 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_013_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_013_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_013_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.17 X,0.17 Y,0.17 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_017_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_017_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_017_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        xlabel={Z Position / \n{nm}},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.19 X,0.19 Y,0.19 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_019_blue2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_019_blue2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_019_blue2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \caption{ Estimated \textsc{Cram\'er Rao} lower bound for blue light
    for X, Y and Z axis (teal, orange and purple lines); grouped by
    different correction Collar settings (top: 0.13, middle: 0.17, bottom:
    0.19) of the Olympus \SI{1.5}{\NA} objective.}
  \label{f:collarb}
\end{figure}


% 
\begin{figure}[!t]
  \begin{subfigure}[t!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 X,0.17 X,0.19 X},
        % legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_013_red2.csv };
        \addplot[color=orange ]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_017_red2.csv};
        \addplot[color=violet ]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_019_red2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 Y,0.17 Y,0.19 Y},
        % legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_013_red2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_017_red2.csv};
        \addplot[color=violet ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_019_red2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        xlabel={Z Position / \n{nm}},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 Z,0.17 Z,0.19 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_013_red2.csv };
        \addplot[color=orange ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_017_red2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_019_red2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \caption{ Estimated \textsc{Cram\'er Rao} lower bound for red light
    for different correction Collar settings (teal: 0.13, orange: 0.17,
    purple: 0.19) of the Olympus \SI{1.5}{\NA} objective; grouped by X, Y
    and Z axis (top, middle, and bottom).}
  \label{f:axesr}
\end{figure}
% 
\begin{figure}[!t]
  \begin{subfigure}[t!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,        
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.13 X,0.13 Y,0.13 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_013_red2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_013_red2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_013_red2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        % xlabel={Z Position / \n{nm}},
        xticklabels={,,},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.17 X,0.17 Y,0.17 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_017_red2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_017_red2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_017_red2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \begin{subfigure}[b!]{0.5\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        ymin=0,
        ymax=60,
        enlargelimits=false,
        smooth,
        grid=both,
        grid style=dashed,
        xlabel={Z Position / \n{nm}},
        ylabel={\textsc{Cram\'er Rao} lower bound / \n{nm}},
        grid=major,
        legend entries={0.19 X,0.19 Y,0.19 Z},
        legend pos = north west,
        ]
        \addplot[color=teal]
        table [ x=n, y=x, col sep=comma ] {crlb/crall_019_red2.csv };
        \addplot[color=orange ]
        table [ x=n, y=y, col sep=comma ] {crlb/crall_019_red2.csv};
        \addplot[color=violet ]
        table [ x=n, y=z, col sep=comma ] {crlb/crall_019_red2.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \caption{ Estimated \textsc{Cram\'er Rao} lower bound for red light
    for X, Y and Z axis (teal, orange and purple lines); grouped by
    different correction Collar settings (top: 0.13, middle: 0.17, bottom:
    0.19) of the Olympus \SI{1.5}{\NA} objective.}
  \label{f:collarr}
\end{figure}


\clearpage\section{Two Dimensional SMLM}\label{s:r:2dsmlm}

\x{In-focus}, one colour, two dimensional \gls{smlm} is performed on
all the samples, and evaluated by \e{ThunderSTORM} via
\e{\x{ImageJ}}. This gives a good \x{x,y precision}; an ideal
reference for the later three dimensional localisation, whose x,y
precision will most likely be much lower.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{npc/npc2048.png}
  \caption{Example overview of a set of two dimensional SMLM data of
    NPCs, the labeled NPC tori are clearly visible.}
  \label{f:npco}
\end{figure}

Figure~\ref{f:npco} and Figure~\ref{f:npcz} show an example overview
(respective zoom) of a set of two dimensional SMLM data of NPCs using
\gls{dstorm} with \gls{gloxy} buffer. The labeled NPC tori are clearly
visible, even the more or less eight-fold symmetry of the
\x{nucleoporin}s is resolved.\\

For comparison Figure~\ref{f:npc} shows a reconstruction of a human
\gls{npc} from \cite{npc} where the eight-fold symmetry is clearly
visible.

\newpage
~ % dirty hack
\begin{figure}[t!]
  \centering
  \includegraphics[width=0.5\textwidth]{npc/npc256.png}
  \caption{Zoom of Figure~\ref{f:npco}, Example of a set of two
    dimensional SMLM data of NPCs; The labeled NPC tori are clearly
    visible, even the more or less eight-fold symmetry of the
    nucleoporins is resolved.}
  \label{f:npcz}
\end{figure}

~ % dirty hack
\begin{figure}[t!]
  \centering
  \includegraphics[width=0.5\textwidth]{npc/npc3.jpg}
  \caption{Cytoplasmic face of the human NPC.  Near-atomic composite
    structure of the NPC generated by docking high-resolution crystal
    structures into a cryoâ€‘ET reconstruction of an intact human NPC. The
    symmetric core, embedded in the nuclear envelope, is decorated with
    NUP358 (red) domains bound to Ran (gray), flexibly projected into the
    cytoplasm, and CFNCs (pink) overlooking the central transport
    channel. Figure and description from \cite{npc}.}
  \label{f:npc}
\end{figure}

\clearpage\section{Three Dimensional SMLM}\label{s:r:ana}

Defocused, one colour, three dimensional \gls{smlm} is performed on some
of the samples, and evaluated as described in
Section~\ref{s:m:mle}. From the stack of 50k microscopy images, one
obtains a list of localisations comprised of position (\tt{x,y,z}),
photon count (\tt{n}), and a fit parameter (\tt{fit}). Where the
\tt{sans serif} typeset letters refer to the variables in the code
listed in this chapter.

In this section I want to describe our data analysis pipeline, in
order to cut down the massive amount of initial localisations---in our
example case over 130k---to distill it to the most meaningful
conclusions.

As a proof of work we used \gls{npc}s as sort of a well defined
biological test target. As these are used frequently for the purpose
of validating a new method, it would be nice to quickly evaluate of
\e{how good are the \gls{npc}s resolved}. The Section~\ref{s:r:ananpc}
is thus dedicated to find some metric for \e{best resolved}
\gls{npc}s.

This analysis is performed in \e{\x{Python}}, and is freely available
in my \e{Git repository} \cite{sie21}; both as a plain \e{Python} file
(\e{.py}) as well as in the format of a \e{\x{Jupyter Notebook}}
(\e{.ipynb}).

A slightly shortened version of the code is also shown in
Appendix~\ref{ch:code} for each Subsection. For the sake of
readability we omit the code sections generating the shown plots, as
they are mostly redundant. Of course the full code is available
online.


\subsection{Import}

Here we import the used packages and the data file we obtain from
running the \gls{smlm} algorithm.


\subsection{Drift Correction}

The \e{\x{drift}} of the setup over time can be estimated using
\e{ImageJ}, and is then imported as \tt{drift}. In the following block
the drift correction is applied to all the 130k localisations, shown
in Figure~\ref{f:2_drift} as 3d plot of all the initial 370k drift
corrected localisations.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{2_drift.png}
  \caption{3d plot of all 370148 drift corrected localisations, colour
    coded by photon count.}
  \label{f:2_drift}
\end{figure}


\subsection{Photon Counts}

As a preliminary step it might prove useful to look at the photon
count statistics, shown in Figure~\ref{f:3_photons}. Here we can
easily see what the supposed intensity of a single molecule is; the
peak, in our case about 2000. Those localisations below may be
considered noise, those far above are probably overlapping or stacked
molecules, so their intensities add up.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{3_photons.png}
  \caption{histogram of the photon count for the localisations.}
  \label{f:3_photons}
\end{figure}


\subsection{Filter}

In this first filter we limit the dataset to the more meaningful
points; like those with intensities between 2k and 7k. Also since we
defocused for \SI{500}{\nano\m}, only those \tt{z} values between 0 and
499 can be considered realistic. Here 0 means directly attached to the
glass substrate, so negative values would be \e{inside} the glass
substrate; and thus need to be discarded as unplausible. The dataset
could be filtered by \tt{min\_fit}, but to our findings this does not
contribute much.

Figure~\ref{f:4_filter} shows a 3d plot of the remaining 154k
localisations after we apply the filter, thus effectively shrinking
down our exemplary data set by about 40\%.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{4_filter.png}
  \caption{3d plot of all 154237 filtered localisations, colour coded
    by photon count.}
  \label{f:4_filter}
\end{figure}


\subsection{Track Particles}

The 50k frames we analyse here are taken with exposure of
\SI{20}{\m\s}, and \SI{10}{\m\s} between consecutive
exposures. Depending on the laser intensity and the buffer composition
the bright state has a specific lifetime $\tau$. This leads to one
exemplary molecule being \e{on} for some \SI{30}{\m\s} (one frame)
while some other is on for \SI{60}{\m\s}; and so appears in two
consecutive frames. Since the molecule in those two frames essentially
is the same, we can \e{track} it over time: effectively averaging the
location if present in multiple frames, thus reducing the amount of
localisations while at the same time increasing their precision.

The parameters \tt{sr} denotes the \e{search range}, how far apart two
consecutive localisations are still considered \e{one} particle, this
has to be adjusted based on the physical setup considering vibrations
and the like.

Figure~\ref{f:5_tracking} shows a 3d plot of the remaining 98k
localisations, after we track the particles. So the \x{tracking} step
further shrinks down our exemplary data set by about 60\%.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{5_tracking.png}
  \caption{3d plot of all 98456 filtered localisations, colour coded by
    photon count.}
  \label{f:5_tracking}
\end{figure}


\section{NPC Analysis}\label{s:r:ananpc}

We use \gls{npc}s as a test target for our method, thus we have some
additional knowledge, like the geometry of each individual \gls{npc}:
they comprise two stacked tori, each about \SI{150}{\nano\m} diameter
(in x,y direction), and \SI{150}{\nano\m} apart (in z direction). Mind
that in Figure~\ref{f:npc}, the reconstruction of a human \gls{npc}
from \cite{npc}, only the Cytoplasmic face is shown. The protein
groups forming the torus are shown in colors on the grey membrane
surface. The second torus is on the core side of the nuclear envelope,
and is not shown here.\\

Now we can group our dataset with close to 100 thousand localisations
to clusters of roughly this size in x,y (set \tt{dim=2}). Note that
for the sake of completeness, we include the possibility of clustering
in 3d to spheres in x,y,z (set \tt{dim=3}), but mind that x,y and z
precision most often greatly varies (see Section~\ref{s:r:crlb}).

The parameter \tt{min\_samples} denotes the minimum amount of
constituents a cluster must have to be considered such.

Figure~\ref{f:5_tracking} shows a 3d plot of the localisations of 658
identified clusters, omitting all the other 35489 localisations as
noise. So the clustering step further shrinks down our exemplary data
set by about 30\%.


\subsection{Clustering}

Figure~\ref{f:6_clustering} shows the localisations of the 658
identified clusters (omitting 35489 localisations as noise, due to not
belonging to a cluster), colour coded by photon count.

In our experiments a density based clustering algorithm \e{dbscan}
\cite{eks96} worked better than \e{kmeans}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{6_clustering.png}
  \caption{3d plot of the localisations of the 658 identified clusters
    (omitting 35489 localisations as noise, due to not belonging to a
    cluster), colour coded by photon count.}
  \label{f:6_clustering}
\end{figure}


\subsection{Cluster Analysis}

For all the localisations within each of these identified clusters, we
now derive the centroid position (\tt{xmean,ymean,zmean}), with
standard deviation (\tt{xvar,yvar,zvar}). This enables the
classification of the within-cluster distribution of localisations,
alas how well they represent the anticipated \gls{npc} geometry.

To obtain this \e{quality}, we compose both the quantity
\tt{ringness}, denoting how well the cluster shapes a ring in x,y
direction; as well as the quantity \tt{twofold}, denoting how well the
cluster resembles two stacked tori in z direction, basically forming a
camel-curve in z direction. To break this down to one scalar each, we
compute the \gls{rms} of the deviations of each localisations radius
from the cluster centre (in x,y direction) from the known \gls{npc}
radius (Lines~20--24). The quantity \tt{twofold} is similarly
comprised of a \gls{rms} deviation of each localisations z value from
the cluster centre (in z direction) from the known NPC height. The
mentioned parameters are thus called \tt{npc\_radius}, respective
\tt{npc\_height}.

Figure~\ref{f:7_filtered_clusters} shows a broad overview of the
location of the cluster centres (not the localisations within), colour
coded by photon count. This should be considered more of a short
sanity check than a profound analysis.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{7_filtered_clusters.png}
  \caption{3d plot of the positions of the 451 filtered clusters,
    colour coded by photon count.}
  \label{f:7_filtered_clusters}
\end{figure}


\subsection{Select Clusters}

Now we possess all the information needed to evaluate the list of
clusters; for example to sort for the lets say 10 most \e{ringlike}
clusters. Or, by setting \tt{sort = 'ringness + twofold'}, we may find
the 10 \e{best} clusters in terms of both \tt{ringness} and
\tt{twofold}---weighted equally---which would comprise the 10
\e{overall best}, thus \e{most \gls{npc} like} clusters.

For sake of completeness we also include the x,y and z variances, even
if they do not comprise a very meaningful parameter in the particular
case due to the \gls{npc}s geometry.

Figure~\ref{f:8_best_filtered_clusters} and
Figure~\ref{f:9_best_filtered_clusters} show a 3d plot of the
localisations within the 10 \e{best} clusters, colour coded by photon
count respective by cluster assignment.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{8_best_filtered_clusters.png}
  \caption{3d plot of the localisations within the 10 \e{best}
    clusters, colour coded by photon count.}
  \label{f:8_best_filtered_clusters}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{9_best_filtered_clusters.png}
  \caption{3d plot of the localisations within the 10 \e{best}
    clusters, colour coded by cluster assignment.}
  \label{f:9_best_filtered_clusters}
\end{figure}


\subsection{X,Y,Z Histograms}\label{s:r:xyzhist}

As a further sanity check, we plot the \x{histogram}s for selected
clusters (\tt{plot\_cluster}), in x,y and z direction; to figure out
if the sorting did work effectively---thus the higher sorted clusters
are indeed \e{better} examples of \gls{npc}s.

Figure~\ref{f:10_xyz_best_filtered_clusters} shows exemplary
histograms of the x,y (right) respective z distribution (left) of the
localisations within the \e{best} cluster (top), the \e{worst}
(bottom) and one in between.

\newpage
~ % dirty hack
\begin{figure}[t!]
  \centering
  cluster 1\\
  \includegraphics[width=0.5\textwidth]{10_histograms_1.png}\\
  cluster 10\\
  \includegraphics[width=0.5\textwidth]{10_histograms_10.png}\\
  cluster 450\\
  \includegraphics[width=0.5\textwidth]{10_histograms_450.png}
  \caption{histogram of the x,y (right) respective z distribution
    (left) of the localisations within the \e{best} cluster (top), the
    \e{worst} (bottom) and one in between.}
  \label{f:10_xyz_best_filtered_clusters}
\end{figure}


\t{In this section I am missing one figure that would show xy and z(x or
y) projection of the NPC to really see if we found the right thing}


\clearpage\section{Dual Colour 3d SMLM}\label{s:r:dcsim}

In order to perform two-colour \gls{smlm} we marked \gls{npc}s and
bead samples with an equal amount of both AF488 and AF647 fluorescence
dyes.

A first measurement using the \gls{gloxy} buffer worked well for the
red channel (for which the Gloxy buffer is designed) but did not lead
to a good \gls{snr} in the blue channel.

Using the \gls{oxea} buffer described in Section~\ref{s:m:oxea}, we
got both channels working, but the overall \gls{snr} proved to be not
good enough for drift analysis via \e{ImageJ}, or even \x{particle
tracking}. There is no way we could try to recover the 3d
transformation relating those data sets under this noisy conditions.

Thus we will analyse simulated data instead: based on three
dimensional random data sets in Section~\ref{s:r:3dsim}, as well as
based on two dimensional \gls{smlm} data sets in
Section~\ref{s:r:2dsim}.


\subsection{Simulation}\label{s:r:3dsim}

In the first and second simulation the transformation relating both
sets simply is a translation, respective a rotation and translation
(rigid). Examples of sets related in such a way are shown in
Figure~\ref{f:transim} as purple and cyan dots on the top row for
solely shifted and in the middle row for shifted and rotated sets
(rigid). In a third simulation, the two sets are related by an affine
transform adding shearing, reflection and scaling, shown in
Figure~\ref{f:transim} as purple and cyan dots on the bottom row.

All three simulations are now evaluated by both the algorithms
\tt{rig()} and \tt{affine()} assuming a rigid respective an affine
transformation. The resulting transformation, thus the projection from
one set to the other is shown as magenta lines in all six sub figures
of Figure~\ref{f:transim}.

\begin{figure*}[!t]
  \vspace{-3em}
  \rotatebox{90}{\b{Shift}}
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \b{Rigid Projection}
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        % label shift = -10pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_rigid_rec_shift/q.dat};
        \addplot3[magenta, only marks, mark=x] table {sim_rigid_rec_shift/pr.dat};
        \addplot3[magenta, mark=x] table {sim_rigid_rec_shift/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_rigid_rec_shift/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  ~
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \b{Affine Projection}
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        % label shift = -10pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_affine_rec_shift/q.dat};
        \addplot3[magenta, only marks, mark=x] table {sim_affine_rec_shift/pr.dat};
        \addplot3[magenta, mark=x] table {sim_affine_rec_shift/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_affine_rec_shift/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \\
  \rotatebox{90}{\b{Rigid}}
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -15pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_rigid_rec_rigid/q.dat};
        \addplot3[magenta, only marks, mark=x] table {sim_rigid_rec_rigid/pr.dat};
        \addplot3[magenta, mark=x] table {sim_rigid_rec_rigid/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_rigid_rec_rigid/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  ~
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -15pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-1,
        xmax=1,
        ymin=-1,
        ymax=1,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_affine_rec_rigid/q.dat};
        \addplot3[magenta, mark=x] table {sim_affine_rec_rigid/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_affine_rec_rigid/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  \\
  \rotatebox{90}{\b{Affine}}
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -5pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-2,
        xmax=2,
        ymin=-2,
        ymax=2,
        grid=major
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_rigid_rec_affine/q.dat};
        \addplot3[magenta, mark=x] table {sim_rigid_rec_affine/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_rigid_rec_affine/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  ~
  \begin{subfigure}[t!]{0.44\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
        enlargelimits=false, smooth,
        grid=both, grid style=dashed,
        xlabel={x / $\mu$m},
        ylabel={y / $\mu$m},
        zlabel={z / $\mu$m},
        label shift = -5pt,
        % legend entries={blue channel, transformed red channel, red channel},
        xmin=-2,
        xmax=2,
        ymin=-2,
        ymax=2,
        grid=major,
        ]
        \addplot3[cyan, only marks, mark=*] table {sim_affine_rec_affine/q.dat};
        \addplot3[magenta, mark=x] table {sim_affine_rec_affine/netz.dat};
        \addplot3[violet, only marks, mark=*] table {sim_affine_rec_affine/p.dat};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}
  % 
  \caption{Demonstration of the recovery of rigid (left) respective
    affine (right) transformations, via recovering localisations of
    simulated two channel \gls{smlm} data; transformation (magenta) from red
    channel (violet) to blue channel (cyan); for the use cases of
    translation (top), rigid transformation (middle) and affine
    transformation (bottom). Obviously a rigid transformation may not
    correctly reconstruct an affine transformed data set (bottom
    left).}
  \label{f:transim}
\end{figure*}

The rigid recovery correctly estimates the rigid transforms of the
first two simulations (top and middle row), but fails completely if
the point clouds are actually \e{not} related by a rigid transform
(bottom row)!

To test the algorithms stability to noise, the simulations are
additionally salted slightly (additive noise to \tt{q}). Due to the
salt; and the fact, that the positions are pseudo-random points, the
resulting transformations are slightly different for every simulation.
The below shown comparison should be understood as an example---yet
well suited to highlighting common problems.

\subsubsection{Shift Projection}

For the first simulation (top row), the initially (true) translation
vector $\b{t}_s^t$ and rotation matrix $\b{R}_s^t$ is:
\begin{equation}
  \b{t}_s^t=
  \begin{pmatrix}
    0 \\
    0.005 \\
    0.003 \\
  \end{pmatrix}
  ,  \b{R}_s^t=
  \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
  \end{pmatrix}
\end{equation}

The under rigid assumption (left) recovered translation vector
$\b{t}_s^r$ and rotation matrix $\b{R}_s^r$ is:
\begin{equation}
  \b{t}_s^r=
  \begin{pmatrix}
    0.0047 \\
    0.0104 \\
    0.0030 \\
  \end{pmatrix}
  ,  \b{R}_s^r=
  \begin{pmatrix}
    0.999 & 0.000 & 0.000 \\
    0.000 & 0.999 & 0.000 \\
    0.000 & 0.000 & 0.999
  \end{pmatrix}
\end{equation}

The under affine assumption (right) recovered translation vector
$\b{t}_s^a$ and rotation matrix $\b{R}_s^a$ is:
\begin{equation}
  \b{t}_s^a=
  \begin{pmatrix}
    0.0050 \\
    0.0108 \\
    0.0030 \\
  \end{pmatrix}
  ,  \b{R}_s^a=
  \begin{pmatrix}
    1.000 & 0.000 & 0.301 \\
    0.000 & 0.999 & -0.148 \\
    0.000 & 0.000 & 1.001
  \end{pmatrix}
\end{equation}

\subsubsection{Rigid Projection}

For the first simulation (top row), the initially (true) translation
vector $\b{t}_r^t$ and rotation matrix $\b{R}_r^t$ is:
\begin{equation}
  \b{t}_r^t=
  \begin{pmatrix}
    0 \\
    0.005 \\
    0.003 \\
  \end{pmatrix}
  ,  \b{R}_r^t=
  \begin{pmatrix}
    0.342 & 0 & -0.940 \\
    0 & 1 & 0 \\
    0.940 & 0 & 0.342
  \end{pmatrix}
\end{equation}

The under rigid assumption (left) recovered translation vector
$\b{t}_r^r$ and rotation matrix $\b{R}_r^r$ is:
\begin{equation}
  \b{t}_r^r=
  \begin{pmatrix}
    0.0017 \\
    0.0103 \\
    0.0077 \\
  \end{pmatrix}
  ,  \b{R}_r^r=
  \begin{pmatrix}
    0.342 & 0.000 & -0.940 \\
    0.000 & 9.999 & 0.000 \\
    0.940 & 0.000 & 0.342
  \end{pmatrix}
\end{equation}

The under affine assumption (right) recovered translation vector
$\b{t}_r^a$ and rotation matrix $\b{R}_r^a$ is:
\begin{equation}
  \b{t}_r^a=
  \begin{pmatrix}
    0.0014 \\
    0.0093 \\
    0.0069 \\
  \end{pmatrix}
  ,  \b{R}_r^a=
  \begin{pmatrix}
    0.3420 & 0.000 & -0.614 \\
    0.000 & 9.999 & 1.014 \\
    0.940 & 0.000 & 1.235
  \end{pmatrix}
\end{equation}

\subsubsection{Affine Projection}

For the first simulation (top row), the initially (true) translation
vector $\b{t}_a^t$ and rotation matrix $\b{R}_a^t$ is:
\begin{equation}
  \b{t}_a^t=
  \begin{pmatrix}
    0 \\
    0.005 \\
    0.003 \\
  \end{pmatrix}
  ,  \b{R}_a^t=
  \begin{pmatrix}
    -0.684 & -0.342 & -0.940 \\
    0.000 & 1.000 & 0.000 \\
    -1.879 & -0.940 & 0.342
  \end{pmatrix}
\end{equation}

The under rigid assumption (left) recovered translation vector
$\b{t}_a^r$ and rotation matrix $\b{R}_a^r$ is:
\begin{equation}
  \b{t}_a^r=
  \begin{pmatrix}
    0.0113 \\
    0.0059 \\
    0.0341 \\
  \end{pmatrix}
  ,  \b{R}_a^r=
  \begin{pmatrix}
    -0.325 & -0.106 & -0.940 \\
    -0.309 & 0.951 & 0.000 \\
    -0.894 & -0.290 & 0.342
  \end{pmatrix}
\end{equation}

The under affine assumption (right) recovered translation vector
$\b{t}_a^a$ and rotation matrix $\b{R}_a^a$ is:
\begin{equation}
  \b{t}_a^a=
  \begin{pmatrix}
    -0.0058 \\
    0.0110 \\
    -0.0129 \\
  \end{pmatrix}
  ,  \b{R}_a^a=
  \begin{pmatrix}
    -0.684 & -0.342 & -0.566 \\
    0.000 & 1.000 & -0.319 \\
    -1.879 & -0.940 & 1.364
  \end{pmatrix}
\end{equation}


\clearpage\subsection{Projected 2d NPC}\label{s:r:2dsim}

Lacking proper 3d dual colour \gls{smlm} data, we choose to use
two-dimensional \e{ThunderSTORM} \gls{smlm} data for a second proof of
work.

A close look on such generated sets already shows interesting
behaviour: the two sets are \e{shifted}. Obviously by utilising
different wavelength regimes in a highly wavelength dependent process
(optical path, refraction, objective, PSF, etc), one will eventually
face some offset.


\subsubsection{Rigid Projection}\label{s:r:dcnpcr}

The rigid recovery worked quite flawlessly, the mean rotation matrix
$\overline{\b{R}}_r$ is almost unity within uncertainty. The mean
translation vector $\overline{\b{t}}_r$ shows a good variance over all
the twelve analysed sets, with mean and standard deviation of:

\begin{equation}
  \overline{\b{t}}_r=
  \begin{pmatrix}
    39 \\
    30 \\
    0 \\
  \end{pmatrix}
  \pm
  \begin{pmatrix}
    10 \\
    4 \\
    0 \\
  \end{pmatrix}
  \si{\micro\m}
\end{equation}

\begin{equation}
  \overline{\b{R}}_r =
  \begin{pmatrix}
    1.0000 & 0.0008 & 0 \\
    -0.0008 & 1.000 & 0 \\
    0 & 0 & 1
  \end{pmatrix}
\end{equation}

\begin{equation}
  \sigma( \b{R}_r ) =
  \begin{pmatrix}
    4\cdot10^{-7} & 4\cdot10^{-4} & 0 \\
    4\cdot10^{-4} & 4\cdot10^{-7} & 0 \\
    0 & 0 & 0
  \end{pmatrix}
\end{equation}

As an example of this rigid transformation, the localisations of the
blue channel (blue $\times$), the red channel (violet $+$) and the
projection from blue channel to red channel channel (magenta $\circ$)
is shown in Figure~\ref{f:npc_rigid}, for one exemplary data set. The
transformed blue channel localisations mostly align well with the red
channel localisations.


\subsubsection{Affine Projection}\label{s:r:dcnpca}

A similar analysis assuming an affine transformation though fails
completely. This is due to the fact that the data sets are projected
onto the z plane for analysis, so are now composing strictly parallel
planes. This leads to the covariance matrices being \e{singular}, so
the affine transform routine fails (or at least heavily crashes
trying) to invert the covariance matrices. At least the results are so
horribly wrong---if at all---that it is highly unlikely to \e{not} get
suspicious immediately. In our case the translation vector is in the
order of millimeters, which is not very plausible for two sets within
the same cell. Thus we omitted the results.

\clearpage
\onecolumn

\begin{figure*}[p]
  \vspace{-5em}
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      width=0.7\textwidth,
      height=0.7\textwidth,
      name=ax1,
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xlabel={X Position / \n{nm}},
      ylabel={Y Position / \n{nm}},
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xmin=0.5e4,
      xmax=0.85e4,
      ymin=0.5e4,
      ymax=0.851e4,
      grid=major,
      thick,
      mark size=8pt,
      ]
      \addplot[cyan, only marks, mark=x] table {npc_rigid/centroid_blue.mat};
      \addplot[violet, only marks, mark=+] table {npc_rigid/centroid_red.mat};
      \addplot[magenta, only marks, mark=o] table {npc_rigid/centroid_blue_transformed.mat};
    \end{axis}
    \begin{axis}[
      width=0.7\textwidth,
      height=0.7\textwidth,
      name=ax2,
      % place second axis relative to first one anchor is south west
      at={($(ax1.north west)+(0,1.5cm)$)},
      enlargelimits=false, smooth,
      grid=both, grid style=dashed,
      xlabel={X Position / \n{nm}},
      ylabel={Y Position / \n{nm}},
      xmin=0,
      xmax=2e4,
      ymin=0,
      ymax=2e4,
      grid=major,
      thick,
      mark size=8pt,
      legend entries={blue channel, red channel, rigid transformation},
      ]
      \addplot[cyan, only marks, mark=x] table {npc_rigid/centroid_blue.mat};
      \addplot[violet, only marks, mark=+] table {npc_rigid/centroid_red.mat};
      \addplot[magenta, only marks, mark=o] table {npc_rigid/centroid_blue_transformed.mat};
      % define coordinates at bottom left and top left of rectangle
      \coordinate (c1) at (axis cs:0.5e4,0.5e4);
      \coordinate (c2) at (axis cs:0.5e4,0.85e4);
      \coordinate (c3) at (axis cs:0.85e4,0.85e4);
      % draw a rectangle
      \draw (c1) rectangle (axis cs:0.85e4,0.85e4);
    \end{axis}
    % draw dashed lines from rectangle in first axis to corners of second
    \draw [dashed] (c2) -- (ax1.north west);
    \draw [dashed] (c3) -- (ax1.north east);
  \end{tikzpicture}

  \caption{Demonstration of a rigid transformation of the
    localisations (magenta {\color{magenta} $\circ$}) from blue channel
    (blue {\color{cyan} $\times$}) to red channel ({\color{violet} $+$});
    the transformed blue channel localisations mostly align well with the
    red channel localisations.}
  
  \label{f:npc_rigid}
\end{figure*}

\twocolumn

% .
% .      |_)                          _)             
% .   _` | |  __|  __| |   |  __|  __| |  _ \  __ \  
% .  (   | |\__ \ (    |   |\__ \\__ \ | (   | |   | 
% . \__,_|_|____/\___|\__,_|____/____/_|\___/ _|  _|
% .
\clearpage\chapter{Discussion \& Conclusion}


\section{Dual Colour Optics}


\subsection{Zernike Modes}


The \textsc{Zernike} modes for both red and blue channel are estimated
via phase retrieval of in-focus measurements of beads at various
depths. This yields a full PSF model to be used for defocus 3d
\gls{smlm}.\\

The image stacks look good, even if not all are perfectly
symmetrical--some errors are to be expected.\\

The estimated \textsc{Zernike} modes of the PSF are mostly plausible;
based on the modes and the order of magnitude.\\

This is further backed by the comparison of the results grouped by the
three correction collar settings $\{0.13,0.17,0.19\}$, in
Figure~\ref{f:zern013}, Figure~\ref{f:zern017} and
Figure~\ref{f:zern019}. It is quite obvious, that the results for both
red and blue channel are in the same order of magnitude---if not quite
similar---for most of the \textsc{Zernike} modes.\\

Yet the phase retrieval program gave the error \e{high residual error}
for both the red and the blue channel when using the correction collar
settings $\{0.17,0.19\}$. This error indicates that the obtained
images are distorted in a way the phase retrieval program cannot
perceive and correct for. There might be many different reasons for
that, a thorough inspection of the theoretical background of the given
phase retrieval program far exceeds the scope of this work. But since
the correction setting is solely meant for enhancing the resulting
images (less distortion), we can conclude that the settings
$\{0.17,0.19\}$ do not work in this way. Even if the setting of $0.17$
is recommended by the manufacturer for our microscope, this might not
give the best results in our downstream pipeline, and the setting of
$0.13$ should be used nevertheless.


\subsection{Correction Collar}

Based on the Figures~\ref{f:axesb} and Figure~\ref{f:collarb}, and
considering the fact---that we are interested in moderately defocusing
(up to say \SI{250}{\nano\meter})---one might conclude, that the most
preferable setting for the correction collar is 0.13.\\

Yet the recommended setting for our microscope setup is 0.17! Based on
the PSF stacks one would have guessed the 0.17 is more sensitive to z
since it changes much more with different z positions than 0.13.\\

As a conclusion we propose The best setting of the correction collar
for the Olympus \SI{1.5}{\NA} objective is shown to be 0.13. Here we
find the preferable compromise between x,y precision and z precision,
in the regime between about 0 and \SI{250}{\nano\meter}.


\section{Three Dimensional SMLM}

The analysis performed in Section~\ref{s:r:ana} is well suited to
greatly reduce the localisations, just by omitting unplausible data
and noise; in our example from initially 370k to below 100k, or to
about 26\%.


\section{NPC Analysis}~\label{s:d:ananpc}

Our approach of fully automatic evaluation of the \gls{npc}
\e{quality}, may well be considered failed.

Nevertheless we might have gained some valuable insight, as some of
the results of the \gls{npc} analysis might still prove themselves
useful as a secondary filters.


\subsection{Define Scalar Quality}

The fully automatic evaluation of the \gls{npc} \e{quality}, shown in
Section~\ref{s:r:ananpc} surfaced mixed results. The key problems
being for one, that there are quite many parameters involved; and
secondly that the analysis proved very susceptible to changes of most
of these parameters.\\

A quick glance at the histograms in Section~\ref{s:r:xyzhist} shows,
that the cluster considered to be the \e{best} does not look better in
fact, than most of the other clusters. We may well consider this
approach failed.\\

Nevertheless we might have gained some valuable insight, into why this
approach doesn't work. Reasons for this may be any and all of the
following, for some of which we may suggest possible improvements.

\begin{description}
\item [numbers] The clusters consist of very few localisations each,
  statistical analysis of so few elements have to be considered
  shaky. More constituents within each cluster would probably make
  this analysis more reliable.
\item [quality] The definitions of the two quality entities
  \tt{ringness} and \tt{twofold}, might not be derived well using
  \gls{rms}. A more sophisticated approach to quantify the clusters
  deviations to our known \gls{npc} geometry might work better, such
  as fitting the histogram in z direction to a \textsc{Gaussian}.
\item [weighting] The equal weighting of \tt{ringness} and
  \tt{twofold} quantities are canceling each other; Some clusters
  might look very \e{ringlike}, but are not at all stacked on top of
  each other, and vica versa. Unequal weighting based on empirical
  fine tuning might lesser this problem, but will most likely not
  solve it.
\end{description}


\subsection{Secondary Filter}

Some of the results of the \gls{npc} analysis might still prove
themselves useful as a secondary filters. In reducing the clusters
until only a few remain, effectively also finds the \e{best}.

\begin{description}
\item [high variance] One might want to exclude clusters with an
  overly high variance, as these might be in fact two \gls{npc}s too
  close to each other to be accounted separately by the clustering
  algorithm.
\item [low variance] Quite similarly we might exclude those clusters
  showing extremely low variance, under suspicion of being well
  concentrated---yet noise, not representing a \gls{npc} at all.
\item [spread] Likewise we may exclude clusters spreading far in z,
  due to our knowledge of the \gls{npc} height, as well as in x,z due
  to the \gls{npc}s well defined radius.
\end{description}

In the end, possessing a list of the clusters position allows for a
much easier way to plot some of them manually, than to zoom in on a
plot of thousands of localisations repeatedly.


\section{Dual Colour Buffer}

The prepared samples, both beads and \gls{npc}s have been evaluated
using \gls{gloxy} buffer and \gls{oxea} buffer.

The two channels (red and blue) showed great differences in blinking
speed, \e{dark state} and \e{bright state} lifetime, Signal and
background magnitude as well as \gls{snr}.

The data obtained from this dual colour three dimensional localisation
was not of high enough precision to be analysed meaningfully. We thus
propose further investigation in buffers used for dual colour SMLM.
  

\section{Dual Colour Projection}

Simply put, the algorithm \tt{rig()} finds the \e{best} rigid
transformation, whatever the real relation is. This poses a serious
caveat for experimental data, since one is usually not in possession
of any form of ground truth to check whether the result is plausible
or not.

\subsection{SMLM Simulations}\label{d:dcsim}

At first glance at the plots in Figure~\ref{f:transim}, the rigid as
well as the shift problem (top and middle row) are similarly well
solved either by rigid or affine assumption; their projection of the
set \tt{q} neatly correspond with set \tt{p}. Also quite obviously the
recovery of a assumed rigid transform of sets \e{not} related in such
a way (bottom row) does not yield a significant solution.\\

A closer inspection of the respective recovered translation vectors
$\b{t}$ and rotation matrices $\b{R}$ in Section~\ref{s:r:dcsim}
enables a deeper understanding of the involved misconceptions---that
ultimately question this approach.


\subsubsection{Shift}

Comparison of the respective recovered translation vectors
$\b{t}_s^{r,a}$ and rotation matrices $\b{R}_s^{r,a}$ to the ground
truth $\b{t}_s^{t}$ and $\b{R}_s^{t}$ show, that both sort of
agree---for solely shifted data sets. The affine projection is a
little farther off.


\subsubsection{Rigid}

Comparison of the respective recovered translation vectors
$\b{t}_r^{r,a}$ to the ground truth $\b{t}_r^{t}$ shows, that even the
rigid recovery does not represent the ground truth well, with the
affine projection being even farther off still.

Yet a comparison of the respective recovered rotation matrices
$\b{R}_r^{r,a}$ to the ground truth $\b{R}_r^{t}$ show good agreement
for the rigid recovery. The affine recovery is slightly off, but
somewhat acceptable.


\subsubsection{Affine}

Comparison of the respective recovered translation vectors
$\b{t}_a^{r,a}$ to the ground truth $\b{t}_a^{t}$ show very little
agreement for both the rigid and the affine recovery.

A comparison of the respective recovered rotation
matrices $\b{R}_a^{r,a}$ to the ground truth $\b{R}_a^{t}$ shows show
good agreement for the affine recovery, with the rigid recovery
completely failing.


\section{Dual Colour Simulation}

Concluding, one best uses an rigid recovery for a rigid problem, or an
affine recovery for an affine problem, as shown in Table~\ref{t:t} and
Table~\ref{t:r}.

\begin{table}[!htb]
  \caption{Quality of the recovered rotation translation vectors
    (transformation) matrices $\b{t}_{s,r,a}^{r,a}$.}\label{t:t}
  \begin{tabularx}{.5\textwidth}{X l r}
    \hhline{===}
    Problem & rig() & affine() \\
    \hline
    Shift & ok & ok \\
    Rigid & bad & bad \\
    Affine & worse & bad \\
    \hhline{===}
  \end{tabularx}
\end{table}

\begin{table}[!htb]
  \caption{Quality of the recovered rotation (transformation) matrices
    $\b{R}_{s,r,a}^{r,a}$}\label{t:r}
  \begin{tabularx}{.5\textwidth}{X l r}
    \hhline{===}
    Problem & rig() & affine() \\
    \hline
    shift & ok & ok \\
    rigid & good & bad \\
    affine & worse & good \\
    \hhline{===}
  \end{tabularx}
\end{table}

Due to the convexity of the problem (there are infinitely many
transformations), the recovery of a translation vector under the
assumption of at least dome rotation involved is not really possible,
as shown in Table~\ref{t:t} and Table~\ref{t:r}. This poses a
dangerous caveat for the dual colour \gls{smlm} analysis, where we
cannot rule out rotations.


\subsection{Projected 2d NPC}

As a second proof of work, we tested both rigid and affine recovery on
several real dual colour \gls{smlm} data sets of two colour in focus
measurements of different cells successively recorded in the same
sample.

Mind that this is a simulation, the actual transformation between both
sets using the \gls{smlm} analysis might look completely different.


\subsubsection{Rigid}

The rigid recovery worked quite flawlessly, the mean rotation matrix
$\overline{\b{R}}_r$ is almost unity within uncertainty. Yet the mean
translation vector $\overline{\b{t}}_r$ shows a high variance (at
least on x axis) over all the twelve analysed sets, with mean and
standard deviation of:

\begin{equation}
  \overline{\b{t}}_r=
  \begin{pmatrix}
    39 \\
    30 \\
    0 \\
  \end{pmatrix}
  \pm
  \begin{pmatrix}
    10 \\
    4 \\
    0 \\
  \end{pmatrix}
  \si{\micro\m}
\end{equation}

\begin{equation}
  \overline{\b{R}}_r =
  \begin{pmatrix}
    1.0000 & 0.0008 & 0 \\
    -0.0008 & 1.000 & 0 \\
    0 & 0 & 1
  \end{pmatrix}
\end{equation}

\begin{equation}
  \sigma( \b{R}_r ) =
  \begin{pmatrix}
    4\cdot10^{-7} & 4\cdot10^{-4} & 0 \\
    4\cdot10^{-4} & 4\cdot10^{-7} & 0 \\
    0 & 0 & 0
  \end{pmatrix}
\end{equation}


\subsubsection{Affine}

A similar analysis assuming an affine transformation though fails
completely, this method simply cannot work on two dimensional data.


\appendix


\onecolumn


\chapter{Code}\label{ch:code}


\section{3d SMLM Analysis: NPC}

\usemintedstyle{
  manni,
  linenos = true,
  frame = single,
  breaklines,
}


\subsection{Import}

\begin{minted}{python}
  #@markdown ##import core
  import pandas as pd
  import matplotlib.pyplot as plt
  import numpy as np
  import matplotlib as mpl
  from mpl_toolkits.mplot3d import Axes3D
  import scipy.io
  from sklearn.cluster import DBSCAN
  from sklearn import metrics
  from sklearn.datasets import make_blobs
  from sklearn.preprocessing import StandardScaler

  #@markdown ##import jupyter
  #%matplotlib ipympl
  #%matplotlib widget
  #%matplotlib interactive
  % matplotlib inline
  import trackpy
  #import sdt
  #from sdt import io, chromatic, multicolor, brightness
  
  ## local
  wd = 'data/210422_npc_red_defocus/'
  data = pd.read_csv( wd + 'cell1_tr1000_def500.csv',
  header = None,
  names=["x", "y", "z", "n", "bg","fit","id","frame"] )
\end{minted}

\subsection{Drift Correction}

\begin{minted}{python}
  #@markdown ## import & scale drift
  #@markdown > set **magnification** via factor in drift.

  drift = pd.read_csv( wd + 'day2_cell1_driftValues.csv')

  drift['Y2']=drift['Y2']*146.6
  drift['Y3']=drift['Y3']*146.6
  drift['X2']=np.round(drift['X2'])
  drift['X3']=np.round(drift['X3'])

  #@markdown ## apply drift correction

  for i in range(len(drift)-1):
  fr=data[(data['frame']>=drift['X2'].iloc[i]) &
  (data['frame']<drift['X2'].iloc[i+1])]
  fr['y']=fr['y']-drift['Y2'].iloc[i]
  fr['x']=fr['x']-drift['Y3'].iloc[i]
  data[(data['frame']>=drift['X2'].iloc[i]) &
  (data['frame']<drift['X2'].iloc[i+1])]=fr
\end{minted}


\subsection{Photon Counts}

\begin{minted}{python}
  #@markdown ## Check: photon counts
  #@markdown > set `max_photons` accordingly (default: 10000).
  max_photons = 10000 #@param {type:"slider", min:0, max:40000, step:1000}
  
  fig = plt.figure()
  plt.hist( data['n'], bins=50, range=( 0, max_photons ) )
\end{minted}


\subsection{Filter}

\begin{minted}{python}
  #@markdown ## filter
  #@markdown > set `min_photons` and `max_photons` accordingly (default: 2000 < photons < 7000).\
  #@markdown > set `min_z` and `max_z` accordingly (default: 0 < z < 499).\
  #@markdown > set `min_fit` accordingly (default: 6e6).
  min_photons = 2000 #@param {type:"slider", min:0, max:40000, step:1000}
  max_photons = 7000 #@param {type:"slider", min:0, max:40000, step:1000}
  min_z = 0 #@param {type:"slider", min:0, max:500, step:1}
  max_z = 384 #@param {type:"slider", min:0, max:500, step:1}
  min_fit = 7192000 #@param {type:"slider", min:0, max:1e7, step:1000}
  
  fdata = data[ ( data['n'] > min_photons ) &
  ( data['n'] < max_photons ) & 
  ( data['z'] > min_z ) &
  ( data['z'] < max_z ) &
  ( data['fit'] < min_fit ) ]
\end{minted}


\subsection{Track Particles}

\begin{minted}{python}
  #@markdown ## track all in x,y
  #@markdown > set `sr` to wanted search range (default: 50).\
  #@markdown > set `mem` to wanted memory (default: 10).
  sr = 50 #@param {type:"slider", min:0, max:100, step:1}
  mem = 10 #@param {type:"slider", min:0, max:100, step:1}
  
  linkedxy = trackpy.link_df( fdata,
  pos_columns = ["x","y","z"],
  search_range = sr,
  memory = mem )
  
  particles = linkedxy.groupby( "particle" ).aggregate( np.mean )
  std_pos = linkedxy.groupby( "particle" ).aggregate( 'std' )
  particles["length"] = linkedxy.groupby( "particle" ).apply( len )
  particles["z_std"] = std_pos['z'].copy()
  particles["x_std"] = std_pos['x'].copy()
  particles["y_std"] = std_pos['y'].copy()
\end{minted}


\clearpage\section{3d SMLM Analysis: NPC}

\subsection{Clustering}

\begin{minted}{python}
  #@markdown ## compute dbscan
  #@markdown > set `dim = 2` for clustering in x and y (default:).\
  #@markdown > set `dim = 3` for experimental clustering in 3d; be aware that x,z and y precision probably vary!\
  #@markdown > set `eps` (default: 200).\
  #@markdown > set `min_samples` (default: 10).
  dim = "2" #@param [2, 3]
  eps = 100 #@param {type:"slider", min:0, max:500, step:10}
  min_samples = 50 #@param {type:"slider", min:1, max:100, step:1}

  alocalisations = localisations.to_numpy()
  alocalisations[ :, 0:2 ]

  db = DBSCAN( eps, min_samples ).fit( alocalisations[ :, 0:int( dim ) ] )
  core_samples_mask = np.zeros_like( db.labels_, dtype=bool )
  core_samples_mask[ db.core_sample_indices_ ] = True
  labels = db.labels_
  localisations[ "cluster" ] = labels

  # count clusters (ignore noise if present)
  n_clusters_ = len( set( labels ) ) - ( 1 if -1 in labels else 0 )
  n_noise_ = list( labels ).count( -1 )

  #print('Estimated number of clusters: %d' % n_clusters_)
  #print('Estimated number of noise points: %d' % n_noise_)

  nlocalisations = localisations.loc[ localisations['cluster'] == -1 ]
  clocalisations = localisations.loc[ localisations['cluster'] != -1 ]
\end{minted}


\subsection{Cluster Analysis}

\begin{minted}{python}
  #@markdown ## analyse clusters
  #@markdown > set `npc_radius` to NPC radius /nm (default: 50).\
  #@markdown > set `npc_radius` to NPC haight /nm (default: 150).
  npc_radius = 50 #@param {type:"slider", min:0, max:500, step:1}
  npc_height = 25 #@param {type:"slider", min:0, max:500, step:1}

  clabels = set(labels)
  cnames = [ "counts", "xmean", "ymean", "zmean", "nmean", "xvar", "yvar", "zvar",
  "nvar", "label", "ringness", "twofold" ]
  clusters = pd.DataFrame( index = clabels, columns = cnames, dtype="float64" )
  clusters[ "label" ] = clabels

  for k in clabels:
  tmp = localisations.loc[ localisations['cluster'] == k ]
  clusters.loc[ k, "counts" ] = len( tmp )
  for label in [ "x", "y", "z", "n" ]:
  clusters.loc[ k, label+"mean"  ] = np.mean( tmp.loc[ :, label ] )
  clusters.loc[ k, label+"var"  ] = np.var( tmp.loc[ :, label ] )

  ## xy: radius (distance to centroid)
  rad = np.sqrt( ( tmp.loc[ :, "x" ] - clusters.loc[ k, "xmean" ] )**2 + 
  ( tmp.loc[ :, "y" ] - clusters.loc[ k, "ymean" ] )**2 )
  ## xy: radius rms deviation from NPC radius
  clusters.loc[ k, "ringness"  ] = np.sqrt( sum( ( rad - npc_radius )**2 ) )

  ## z: radius (distance to centroid)
  rad = abs( tmp.loc[ :, "z" ] - clusters.loc[ k, "zmean" ] )
  ## z: radius rms deviation from NPC radius
  clusters.loc[ k, "twofold"  ] = np.sqrt( sum( ( rad - npc_height )**2 ) )

  #@markdown ## filter clusters
  #@markdown > set `count_threshold` to min elements (counts) in cluster (default: 30)\
  #@markdown > set `diameter_threshold` to max x,y (radius) deviation of cluster from NPC diameter (default: 200)\
  #@markdown > set `twofold_threshold` to max z (radius) deviation of cluster from NPC height (default: 200)\
  #@markdown > set `xyvar_threshold` to wanted x,y variance (default: 1e4)\
  #@markdown > set `zvar_threshold` to wanted z variance (default: 1e4)
  count_threshold = 100 #@param {type:"slider", min:0, max:200, step:1}
  diameter_threshold = 500 #@param {type:"slider", min:0, max:500, step:10}
  twofold_threshold = 1000 #@param {type:"slider", min:0, max:1000, step:10}
  xyvar_threshold = 100000 #@param {type:"slider", min:0, max:1e5, step:1e3}
  zvar_threshold = 100000 #@param {type:"slider", min:0, max:1e5, step:1e3}

  fclusters = clusters[ ( clusters['counts'] < count_threshold ) &
  ( clusters['ringness'] < diameter_threshold ) &
  ( clusters['twofold'] < twofold_threshold ) &
  ( clusters['xvar'] < xyvar_threshold ) & 
  ( clusters['yvar'] < xyvar_threshold ) &
  ( clusters['zvar'] < zvar_threshold ) ]
\end{minted}


\subsection{Select Clusters}

\begin{minted}{python}
  #@markdown ## select best clusters & plot localisations
  #@markdown > set `show_clusters` to wanted number of best clusters (default: 100).\
  #@markdown > set `sort` to sort the best clusters (default: ringness + twofold).
  show_clusters = 10 #@param {type:"slider", min:0, max:1000, step:1}
  sort = 'ringness + twofold' #@param [ "ringness + twofold", "twofold", "ringness", "xyvar" , "xvar" ]

  if sort == "xvar": # sort by variance
  sclusters = fclusters.sort_values( "xvar" )
  elif sort == "xyvar": # sort by x and y variance using least squares
  sclusters = fclusters.loc[
  ( fclusters.xvar ** 2 + fclusters.yvar ** 2 ).sort_values().index ]
  elif sort == "ringness": # sort by ringness (deviation to ringness)
  sclusters = fclusters.sort_values( "ringness" )
  elif sort == "twofold": # sort by ringness (deviation to ringness)
  sclusters = fclusters.sort_values( "twofold" )
  elif sort == "ringness + twofold": # sort by ringness (deviation to ringness)
  sclusters = fclusters.loc[
  ( fclusters.twofold ** 2 + fclusters.ringness ** 2 ).sort_values().index ]

  show_clusters = min( show_clusters, len( sclusters ) )
  selected_clusters = sclusters["label"].iloc[ 0:show_clusters ]

  fig = plt.figure()
  ax = fig.add_subplot( projection = '3d' )
  for clus in selected_clusters:
  flocalisations = localisations[ ( localisations['cluster'] == clus ) ]
  ff = ax.scatter( flocalisations['x'],
  flocalisations['y'],
  flocalisations['z'],
  s=1 ,c = flocalisations['n'] )
\end{minted}


\subsection{X,Y,Z Histograms}

\begin{minted}{python}
  #@markdown ## Check: z distribution
  #@markdown > set `plot_cluster` to wanted cluster (default: 0).
  plot_cluster = 3  #@param {type:"slider", min:0, max:100, step:1}
  plot_cluster = min( plot_cluster, len( sclusters ) -1 )

  tmp = localisations.loc[ localisations['cluster'] == 
  sclusters.loc[ sclusters.index[ plot_cluster ],
  "label" ] ]

  z = tmp.z - np.mean( tmp.z )

  fig, axes = plt.subplots(2, 1, figsize=(4, 7) ) # figsize=(4, 12)

  axes[0].hist( tmp.z - np.mean( tmp.z ) )
  axes[0].set_xlabel('z / nm')
  axes[0].set_ylabel('counts')
  #axes[0].set_title( 'z' )

  axes[1].hist( tmp.x - np.mean( tmp.x ) )
  axes[1].hist( tmp.y - np.mean( tmp.y ) )
\end{minted}


\clearpage\section{Dual Colour 3d SMLM}\label{s:c:dc}


\subsection{Cockpit: cockpit.m}\label{s:c:cockpit}

\begin{minted}{octave}
#!/bin/octave
## images fluorescence microscopy / 3d position / offsets.
## splice red/green/blank fluorescence microscopy images already located
## into red/green matrices for further analysis, find rigid transform,
## do statistics on all files.
## @ moritz siegel

## init
close all
clear all
clc
graphics_toolkit('gnuplot')
#graphics_toolkit('qt')
#graphics_toolkit('fltk')

## \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
## soft settings \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
global hd = "~/biophysics" # parent directory
global wd = "data/210318_beads_2_colors_in_focus"
global fn = "position"
global nn = ""; # additional luminosity suffix  ( default: "" )
method = "rigid"; # /char, "rigid","affine", method to reconstruct
global minpts = 10; # minimum number of points needed in its neighbourhood to consider it as a valid data(not noise). ( default: 3 )
global dist = 300; #/nm, distance on which neighbourhood is calculated.( default: 200 )
nmax = 15; #/num, maximum number of files analysed.( default: 10 )
global verbose = true; # /bool, plot for error checking? ( default: true )
exclude = [ 6, 7, 8, 11, 12 ]
channel_order0 = [ 0, 1, 2 ];
channel_order = repmat( channel_order0, nmax, 1 );
channel_order( 3, : ) = [ 2, 0, 1 ];
channel_order( 4, : ) = [ 1, 2, 0 ];
channel_order( 6, : ) = [ 2, 0, 1 ];
channel_order( 7, : ) = [ 1, 2, 0 ];
channel_order( 8, : ) = [ 2, 0, 1 ];
channel_order( 12, : ) = [ 2, 0, 1 ];
## end of settings: hands off /////////////////////////////////////////////////
## ///////////////////////////////////////////////////////////////////////////

disp( 'warmup \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ' );
## lets move it move it
addpath( hd ) # function & stuff needed
stamp = strftime("%Y_%m_%d_%H%M%S", localtime (time ())); # create timestamp for saving files
global nwd = sprintf( "%s/%s/all_%s%s%s", hd, wd, method, stamp, nn ); # concat working dir
mkdir( nwd )
chdir( nwd )
global rf = fopen ( "kockpit.log", "w" );

disp( 'cycle \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ' );
rotations = nan( nmax, 3, 3 );
translations = nan( nmax, 3 );
for n = 1 : nmax
  if ( any( exclude == n ) )
    disp( sprintf( "    warning: skipping file positions%d.csv", n ) );
    continue
  endif
  disp( sprintf( "    importing positions%d.csv", n ) );
  disp( '    load \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ' );
  
  ## "id","frame","x [nm]","y [nm]","sigma [nm]","intensity [photon]","offset [photon]","bkgstd [photon]","uncertainty [nm]"
  try
    pos = csvread( sprintf( "%s/%s/%s%d.csv", hd, wd, fn, n ) );
  catch
    continue
  end_try_catch
  
  
  disp( '    analyse \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ' );
  
  [ centroid_red, centroid_blue_transformed, centroid_blue, red, blue, rotation, translation ] = ampel( pos, channel_order( n, : ), n, method );
  
  ## save optimal rigid transform for comparison
  rotations( n, :, : ) = rotation;
  translations( n, : ) = translation;
endfor 
\end{minted}


\subsection{Splice Channels: ampel.m}\label{s:c:ampel}

\begin{minted}{octave}
#!/bin/octave
function[ centroid_red, centroid_blue_transformed, centroid_blue, red, blue, rotation, translation ] = ampel( pos, channel_order, n, method );
  ## This function "ampel" splices the given table including 3d positions
  ## etc from images of twocolor fluorescence microscopy into red & blue
  ## color chanels based on the frame number. It uses "dbscan" to cluster
  ## the images, and sverages the positions within each
  ## cluster. Depending on "method" either finds best rigid transform, or
  ## best affine transform correlating the red and blue sets via least
  ## squares (singular-value-decomposition).
  ## @ moritz siegel
  
  global nwd
  global rf
  global minpts
  global dist

  ## sort red/blue/empty of many frames.
  red = blue = empty = zeros( size( pos ));
  nb = nr = ne = 1;
  for k = 1 : size( pos, 1 )
    
    ## exclude blank lines (text).
    if ( all( pos( k, : ) == 0 ) )
      disp( sprintf( 'warning: line %d is empty; skipping.', k ));
      fprintf( rf, 'warning: empty line; skipping.\n' );
      continue
    endif
    
    ## red pill / blue pill?
    channel = mod( pos( k, 2 ), 3 );
    switch ( channel )
      case channel_order(1)
        blue( nb, : ) = pos( k, : );
        nb = nb + 1;
      case channel_order(2)
        empty( ne, : ) = pos( k, : );
        ne = ne + 1;
      case channel_order(3)
        red( nr, : ) = pos( k, : );
        nr = nr + 1;
    endswitch
  endfor
  disp( sprintf( 'sorted localisations:\n %d red\n %d blue\n %d empty', nr, nb, ne ) );
  fprintf( rf, 'sorted localisations:\n %d red\n %d blue\n %d empty\n', nr, nb, ne );

  ## analyse clusters & average centroids.
  [ assignments_blue, c_blue ] = dbscan( blue( 1:300, 3:4 ), minpts, dist );
  for k = 1 : c_blue
    idx = find( assignments_blue == k );
    centroid_blue( k, 1:2 ) = mean( blue( idx, 3:4 ), 1 );
  endfor
  [ assignments_red, c_red ] = dbscan( red( 1:300, 3:4 ), minpts, dist );
  for k = 1 : c_red
    idx = find( assignments_red == k );
    centroid_red( k, 1:2 ) = mean( red( idx, 3:4 ), 1 );
  endfor

  ## need to ditch clusters if the sets are not equally sized.
  assert( c_red == c_blue, "clusters are not equally sized" );

  ## recover transform.
  switch( method )
    case "rigid"
      ## we only have 2d data currently, introduce linear dependent z component.
      centroid_red = [ centroid_red, zeros( c_red, 1 ) ]
      centroid_blue = [ centroid_blue, zeros( c_blue, 1 ) ]
      [ rotation, translation ] = rig( centroid_blue, centroid_red )
    case "affine"
      ## we only have 2d data currently, introduce noise for z component,
      ## matrix cant be singular, else cholesky decomposition fails.
      z = 1 + 1e-3 * rand( c_red, 1 ); 
      centroid_red = [ centroid_red, z ];
      centroid_blue = [ centroid_blue, z ];
      [ rotation, translation ] = affine( centroid_blue, centroid_red );
  endswitch

  ## transform blue set to red set.
  centroid_blue_transformed = ( rotation * centroid_blue' )' + translation;

endfunction
\end{minted}


\subsection{Rigid Transformation: rig.m}\label{s:c:rig}

\begin{minted}{octave}
  #!/bin/octave
  function [ rotation, translation, s ] = rig( p, q )
  ## this function "rig(p,q)" finds the optimal rigid transform in
  ## 3-dimensional euclidian space, using least squares and
  ## single-value-decomposition. Given a 3xn matrix (set of n 3d
  ## positions), it returns the rotation matrtix "rotation", and the
  ## translation vector "translation".
  ##
  ## K. S. Arun, T. S. Huang and S. D. Blostein, "Least-Squares Fitting of
  ## Two 3-D Point Sets," in IEEE Transactions on Pattern Analysis and
  ## Machine Intelligence, vol. PAMI-9, no. 5, pp. 698-700, Sept. 1987,
  ## doi: 10.1109/TPAMI.1987.4767965.
  ##
  ## moritz siegel @ 210322

  ## check stuff.
  assert( nargin == 2 && size( p ) == size( q ), ...
  "need 2 identical input matrices\n" );
  assert( size( p, 2 ) == 3, "input matrix p must be nx3\n" );
  assert( size( q, 2 ) == 3, "input matrix q must be nx3\n" );
  n = size( p, 1 );
  assert( n > 2, "need at least 3 points\n" );

  ## 1) center to get rid of translation.
  centroid_p = mean( p, 1 );
  centroid_q = mean( q, 1 );
  p_shifted = p - repmat( centroid_p, n, 1 );
  q_shifted = q - repmat( centroid_q, n, 1 );

  ## 2) solve least squares problem for best rotation.
  ## -------------------------------------------------
  
  ## covariance matrix.
  h = p_shifted' * q_shifted;
  
  ## singular value decomposition.
  [ u, s, v ] = svd( h );
  rotation = v * u'

  ## reflection? theres more to that.
  if ( det( rotation ) < 0 )
  printf( "warning: det(r) < 0\n" );
  if ( any( s( : ) ) < 0 )
  printf( "found reflection, correcting.\n" );
  v( :, 3 ) = -v( :, 3 );
  rotation = v * u';
  else
  printf( "error: single-value-decomposition failed! \
  provided data seems is too noisy for least-squares\n." );  
  endif
  endif

  ## 3) compute translation.
  translation = centroid_q - ( rotation * centroid_p' )';
  
  endfunction
\end{minted}


\subsection{Affine Transformation: affine.m}\label{s:c:affine}

\begin{minted}{octave}
#!/bin/octave
function [ affine_rotation, translation, s ] = affine( p, q )
  ## this function "affine(p,q)" finds the optimal affine transform in
  ## 3-dimensional euclidian space, using least squares and
  ## single-value-decomposition. Given a 3xn matrix (set of n 3d
  ## positions), it returns and the rotation matrtix "affine_rotation",
  ## and the translation vector "translation".
  ##
  ## K. S. Arun, T. S. Huang and S. D. Blostein, "Least-Squares Fitting of
  ## Two 3-D Point Sets," in IEEE Transactions on Pattern Analysis and
  ## Machine Intelligence, vol. PAMI-9, no. 5, pp. 698-700, Sept. 1987,
  ## doi: 10.1109/TPAMI.1987.4767965.
  ##
  ## Berthold K. P. Horn, "Closed-form solution of absolute orientation
  ## using unit quaternions," J. Opt. Soc. Am. A 4, 629-642 (1987)
  ##
  ## @ moritz siegel

  global hd
  global wd
  global nwd
  
  ## check stuff.
  assert( nargin == 2 && size( p ) == size( q ), ...
          "need 2 identical input matrices\n" );
  assert( size( p, 2 ) == 3, "input matrix p must be nx3\n" );
  assert( size( q, 2 ) == 3, "input matrix q must be nx3\n" );
  n = size( p, 1 );
  assert( n > 2, "need at least 3 points\n" );

  ## 1) center to get rid of translation.
  centroid_p = mean( p, 1 );
  centroid_q = mean( q, 1 );
  p_shifted = p - repmat( centroid_p, n, 1 );
  q_shifted = q - repmat( centroid_q, n, 1 );
  
  ## 2) orthogonal reduction.
  ## ------------------------
  
  ## variance (?) matrices.
  s_p = p_shifted' * p_shifted;
  s_q = q_shifted' * q_shifted;

  ## square-roots of the covariance matrices.
  ## choleski decomposition: "A -> LL*" , any advantage over sqrtm()?
  #s_sqrt_p = sqrtm( s_p );
  #s_sqrt_q = sqrtm( s_q );
  s_sqrt_p = chol( s_p, "lower" );
  s_sqrt_q = chol( s_q, "lower" );
  
  ## left division. "x\y" is conceptually equivalent to the expression
  ## "inv(x) * y" but it is computed without forming the inverse of x.
  ## if the system is not square, or if the coefficient matrix is
  ## singular, a minimum norm solution is computed.
  p_orthogonal = ( s_sqrt_p \ p_shifted' )';
  q_orthogonal = ( s_sqrt_q \ q_shifted' )';
  
  ## "p" and "q" are now solely related by a rotational matrix
  ## "r = s_inv_sqrt_q * affine * s_sqrt_p" (no inverse!).

  ## 3) solve least squares problem for best rotation.
  ## -------------------------------------------------
  
  ## covariance matrix again.
  h = p_orthogonal' * q_orthogonal;

  ## singular value decomposition.
  [ u, s, v ] = svd( h );
  rotation = v * u';

  ## reflection? theres more to that.
  if ( det( rotation ) < 0 )
    printf( "warning: det(rotation) < 0\n" );
    if ( any( s( : ) ) < 0 )
      printf( "found reflection, correcting.\n" );
      v( :, 3 ) = - v( :, 3 );
      rotation = v * u';
    else
      printf( "error: single-value-decomposition might have failed! \
provided data seems is too noisy for least-squares.\n" );  
    endif
  endif

  ## 4)  reverse the rotation to the non-orthogonal affine transform using
  ## right division: "x/y" is conceptually equivalent to the expression
  ## "x * inv(y)" but it is computed without forming the inverse of x.
  affine_rotation = ( s_sqrt_q * rotation ) / s_sqrt_p;
  
  ## 5) compute translation.
  translation = centroid_q - ( affine_rotation * centroid_p' )';
  
  ## save stuff for plotting.
  ## chdir( nwd )
  ## save p_shifted.mat p_shifted;
  ## save q_shifted.mat q_shifted;
  ## save p_orthogonal.mat p_orthogonal;
  ## save q_orthogonal.mat q_orthogonal;
  ## save rotation.mat rotation
  ## save affine_rotation.mat affine_rotation
  ## save translation.mat translation
  
endfunction
\end{minted}

\subsection{Clustering: dbscan.m}\label{s:c:dbscan}
\begin{minted}{octave}
#!/bin/octave
## This reposetory contains a simple implementation of DBSCAN algorithm
## using GNU OCTAVE.  DBSCAN is a popular clustering algorithm. It
## creates clusters on a spatial data depending on two parameters:
## MinPoints: minimum number of points needed in its neighbourhood to
## consider it as a valid data(not noise).  EPS: A distance on which
## neighbourhood is calculated.
## For more info:
## https://github.com/devil1993/DBSCAN
## https://en.wikipedia.org/wiki/DBSCAN
## http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=1A6A7A85AF3F43BCBF66D847FEC8F8C5?doi=10.1.1.121.9220&rep=rep1&type=pdf
function [assignments,C] = dbscan(X,minpts,EPS)
  C = 0;
  assignments = zeros(size(X)(1),1);
  clustered = zeros(size(X)(1),1);
  for i=1: size(X)(1)
    if(clustered(i)==1)
      continue;
    endif
    clustered(i)=1;
    isneighbour = [];
    neighbourcount = 0;
    for j=1: size(X)(1)
      dist = sqrt(sum((X(i,:)-X(j,:)).^2));
      if(dist<EPS)
        neighbourcount++;
        isneighbour = [isneighbour j];
      endif
    endfor
    if(neighbourcount<minpts)
      continue;
    else
      C++;
      assignments(i) = C;
      for k=isneighbour
        if(clustered(k)==0)
          clustered(k) = 1;
          _isneighbour = [];
          _neighbourcount = 0;
          for j=1: size(X)(1)
            dist = sqrt(sum((X(k,:)-X(j,:)).^2));
            if(dist<EPS)
              _neighbourcount++;
              _isneighbour = [_isneighbour j];
            endif
          endfor
          if(_neighbourcount>=minpts)
            isneighbour = [isneighbour _isneighbour];
          endif
        endif
        assignments(k) = C;
      endfor
    endif
  endfor
endfunction
\end{minted}

\subsection{Simulate Dual Colour 3d SMLM Data: simulate.m}\label{s:c:sim}
\begin{minted}{octave}
#!/bin/octave
## @ moritz siegel

clear all
close all
clc
graphics_toolkit('gnuplot')
#graphics_toolkit('qt')
#graphics_toolkit('fltk')

## \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
## soft settings \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
global hd = "~/biophysics"; # parent directory
global wd = "data";
global nn = "AFFINE"; # additional luminosity suffix  ( default: "" )
method = "affine"; # /char, "rigid","affine", method to reconstruct
#method = "affine"; # /char, "rigid","affine", method to reconstruct
eps = 1e-8; # precision ( default: 1e-8 )
## end of settings: hands off /////////////////////////////////////////////////
## ///////////////////////////////////////////////////////////////////////////


disp( 'init \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ' );

## lets move it move it.
addpath( hd ) # function & stuff needed
stamp = strftime("%Y_%m_%d_%H%M%S", localtime (time ())); # create timestamp for saving files
global nwd = sprintf( "%s/%s/simulation_%s_%s_%s", hd, wd, method, stamp, nn ); # concat working dir
mkdir( nwd )
chdir( nwd )

## init first point cloud. introduce noise for z component, matrix cant
## be singular (e.g. points on a plane), else cholesky decomposition fails.
n = 100;
theta = 100 * rand( n, 1 );
p = [ cos( theta ), sin( theta ), 1e-3 * rand( size( theta ) ) ];

## introduce noise
salt = [ 1e-2*rand( size( theta ) ), 1e-2*rand( size( theta ) ), 1e-5*rand( size( theta ) ) ];
q = p + salt;

## define affine transforms & derive second point cloud.
simulated_translation = [ 0, 0.005, 0.003 ];
reflect = [ -1, 0, 0; 0, 1, 0; 0, 0, 1 ];
scale = [ 2, 0, 0; 0, 1, 0; 0, 0, 1 ];
theta = 70;
rot = [ cosd(theta), 0, -sind(theta); 0, 1, 0; sind(theta), 0, cosd(theta) ];
shear = [ 1, 0.5, 0; 0, 1, 0; 0, 0, 1 ];
simulated_transform = eye( 3 );
simulated_transform = simulated_transform * rot;
simulated_transform = simulated_transform * reflect;
simulated_transform = simulated_transform * scale;
simulated_transform = simulated_transform * shear;
q = ( simulated_transform * q' )';
q = q + simulated_translation;

## check determinant.
#assert( det( simulated_transform ) > 0, "det( simulated_transform ) <= 0, rerun" );


disp( 'analyse \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ' );

## recover transform
switch( method )
case "rigid"
    [ rekovered_transform, rekovered_translation ] = rig( p, q );
case "affine"
    [ rekovered_transform, rekovered_translation ] = affine( p, q );
endswitch

if ( any( any( ( simulated_transform - rekovered_transform ) > eps ) ) )
  disp( "warning: failed to recover affine transform" );
endif
\end{minted}


\twocolumn

% .
% .  |    _) |     
% .  __ \  | __ \  
% .  |   | | |   | 
% . _.__/ _|_.__/
% .
\clearpage

\bibliography{bibliography}

\bibliographystyle{apalike} % 'alpha' for 3 letters + year

% .
% .  |_)      |        
% .  | |  __| __|  __| 
% .  | |\__ \ |  \__ \ 
% . _|_|____/\__|____/ 
% .
\clearpage \listoftables


\clearpage \listoffigures


% \clearpage \listofalgorithms
% \addcontentsline{toc}{chapter}{List of Algorithms}


% \clearpage \listoflistings

% .
% .        |                                  
% .   _` | |  _ \   __|  __|  _` |  __| |   | 
% .  (   | | (   |\__ \\__ \ (   | |    |   | 
% . \__, |_|\___/ ____/____/\__,_|_|   \__, | 
% . |___/                              ____/  
% .
\onecolumn

% \glsaddallunused % add all unused terms to the glossary without including a phantom page number
\clearpage \printacronyms

% .
% . _)           |            
% .  | __ \   _` |  _ \\ \  / 
% .  | |   | (   |  __/ `  <  
% . _|_|  _|\__,_|\___| _/\_\ 
% .
\clearpage \printindex

\t{index}

% .
% .  |   |                          | 
% .  __| __ \   _ \   _ \ __ \   _` | 
% .  |   | | |  __/   __/ |   | (   | 
% . \__|_| |_|\___| \___|_|  _|\__,_|
% .
\end{document}
% LocalWords:  Universit Velas scmos tirf ImageJ ThunderSTORM dstorm
% LocalWords:  mle fminunc Noll gloxy Sigma-Aldrich pbs oxea OxyFlour
% LocalWords:  OxyFlourTM Oxyrase DL-lactate -- NaOH. PSFs Rao crlb -
% LocalWords:  crlb.m svd simulate.m cockpit.m ampel.m dbscan.m Alexa
% LocalWords:  minpts NaOH OxyFluor snr linestyles nucleoporin .py sr
% LocalWords:  .ipynb dbscan kmeans xmean ymean zmean xvar yvar zvar
% LocalWords:  ringness gls defocusing doesn ok manni linenos rig.m
% LocalWords:  affine.m
